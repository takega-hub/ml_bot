"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ª—É—á—à–∏—Ö MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç 15m –∏ 1h –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
–ë–ï–ó —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è MTF —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.
"""
import argparse
import subprocess
import sys
import json
import logging
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any
import traceback

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_file = f'predict_mtf_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ—Ç–æ–º
from bot.state import BotState


class MTFPredictor:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ª—É—á—à–∏—Ö MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(
        self,
        symbols: List[str],
        days: int = 30,
        output_dir: str = "mtf_predictions",
        top_n: int = 10,
        skip_testing: bool = False,
    ):
        self.symbols = [s.upper() for s in symbols]
        self.days = days
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.top_n = top_n
        self.skip_testing = skip_testing
        
        self.python_exe = sys.executable
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.single_results: Optional[pd.DataFrame] = None
        self.predictions: Dict[str, pd.DataFrame] = {}
        self.best_combinations: Dict[str, Dict[str, Any]] = {}
        
        # –û—à–∏–±–∫–∏
        self.errors: List[Dict[str, Any]] = []
    
    def log_error(self, stage: str, symbol: str, error: Exception):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É"""
        error_info = {
            "timestamp": datetime.now().isoformat(),
            "stage": stage,
            "symbol": symbol,
            "error": str(error),
            "traceback": traceback.format_exc()
        }
        self.errors.append(error_info)
        logger.error(f"[{stage}] {symbol}: {error}", exc_info=True)
    
    def check_data_freshness(self, file_path: Path) -> Tuple[bool, bool]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–µ–∂–µ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_fresh, has_all_symbols)
        """
        if not file_path.exists():
            return False, False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ñ–∞–π–ª–∞ (1 –¥–µ–Ω—å = 86400 —Å–µ–∫—É–Ω–¥)
        file_time = file_path.stat().st_mtime
        current_time = datetime.now().timestamp()
        age_hours = (current_time - file_time) / 3600
        
        is_fresh = age_hours < 24  # –ú–µ–Ω—å—à–µ 24 —á–∞—Å–æ–≤
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
        try:
            df = pd.read_csv(file_path)
            if 'symbol' not in df.columns:
                return is_fresh, False
            
            file_symbols = set(df['symbol'].unique())
            required_symbols = set(self.symbols)
            has_all_symbols = required_symbols.issubset(file_symbols)
            
            missing_symbols = required_symbols - file_symbols
            if missing_symbols:
                logger.info(f"[TESTING] –í —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è: {', '.join(missing_symbols)}")
            
            return is_fresh, has_all_symbols
        except Exception as e:
            logger.warning(f"[TESTING] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return False, False
    
    def test_single_models(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ (15m –∏ 1h) –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        logger.info("[TESTING] –ü–æ–∏—Å–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        logger.info(f"[TESTING] –°–∏–º–≤–æ–ª—ã: {', '.join(self.symbols)}")
        logger.info(f"[TESTING] –î–Ω–∏ –±—ç–∫—Ç–µ—Å—Ç–∞: {self.days}")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        comparison_files = sorted(
            Path(".").glob("ml_models_comparison_*.csv"),
            key=lambda p: p.stat().st_mtime if p.exists() else 0,
            reverse=True
        )
        
        symbols_to_test = []
        existing_data = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º existing_data, –µ—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å
        if comparison_files:
            try:
                existing_data = pd.read_csv(comparison_files[0])
            except:
                existing_data = None
        
        if comparison_files and self.skip_testing:
            # –†–µ–∂–∏–º –ø—Ä–æ–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            logger.info(f"[TESTING] –ü—Ä–æ–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª: {comparison_files[0]}")
            try:
                self.single_results = pd.read_csv(comparison_files[0])
                logger.info(f"[TESTING] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞")
                return True
            except Exception as e:
                logger.warning(f"[TESTING] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞: {e}")
                return False
        
        if comparison_files:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
            latest_file = comparison_files[0]
            is_fresh, has_all_symbols = self.check_data_freshness(latest_file)
            
            if is_fresh and has_all_symbols:
                # –î–∞–Ω–Ω—ã–µ —Å–≤–µ–∂–∏–µ –∏ –ø–æ–ª–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                logger.info(f"[TESTING] –ù–∞–π–¥–µ–Ω —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {latest_file}")
                if existing_data is not None:
                    self.single_results = existing_data
                    logger.info(f"[TESTING] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return True
                else:
                    # –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ - —Å–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–Ω–æ–≤–æ
                    logger.warning(f"[TESTING] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ - —Å–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–Ω–æ–≤–æ")
                    symbols_to_test = self.symbols.copy()
            
            elif not is_fresh:
                # –î–∞–Ω–Ω—ã–µ —É—Å—Ç–∞—Ä–µ–ª–∏ - –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ
                logger.info(f"[TESTING] –î–∞–Ω–Ω—ã–µ —É—Å—Ç–∞—Ä–µ–ª–∏ (—Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
                symbols_to_test = self.symbols.copy()
            elif not has_all_symbols:
                # –î–∞–Ω–Ω—ã–µ —Å–≤–µ–∂–∏–µ, –Ω–æ –Ω–µ–ø–æ–ª–Ω—ã–µ - —Å–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
                if existing_data is not None:
                    existing_symbols = set(existing_data['symbol'].unique())
                    symbols_to_test = [s for s in self.symbols if s not in existing_symbols]
                    logger.info(f"[TESTING] –î–∞–Ω–Ω—ã–µ —Å–≤–µ–∂–∏–µ, –Ω–æ –Ω–µ–ø–æ–ª–Ω—ã–µ. –ù—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è: {', '.join(symbols_to_test)}")
                else:
                    logger.warning(f"[TESTING] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ - —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ")
                    symbols_to_test = self.symbols.copy()
        else:
            # –§–∞–π–ª–∞ –Ω–µ—Ç - —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            logger.info("[TESTING] –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω - —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö")
            symbols_to_test = self.symbols.copy()
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
        if not symbols_to_test:
            # –î–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å –∏ —Å–≤–µ–∂–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            if existing_data is not None:
                self.single_results = existing_data
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
                try:
                    self.single_results = pd.read_csv(comparison_files[0])
                except Exception as e:
                    logger.error(f"[TESTING] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
                    return False
            
            logger.info(f"[TESTING] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ: {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return True
        
        # –ù—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤
        logger.info(f"[TESTING] –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤: {', '.join(symbols_to_test)}")
        
        try:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω—É–∂–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            cmd = [
                self.python_exe,
                "compare_ml_models.py",
                "--symbols", ",".join(symbols_to_test),
                "--days", str(self.days),
                "--output", "csv",
                "--interval", "15m",  # –ë–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
                "--detailed-analysis"
            ]
            
            logger.info(f"[TESTING] –ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',  # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                    timeout=7200  # 2 —á–∞—Å–∞ —Ç–∞–π–º–∞—É—Ç
                )
            except Exception as e:
                logger.warning(f"[TESTING] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}")
                result = None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–∑–¥–∞–Ω –ª–∏ —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
            comparison_files_after = sorted(
                Path(".").glob("ml_models_comparison_*.csv"),
                key=lambda p: p.stat().st_mtime if p.exists() else 0,
                reverse=True
            )
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–≥–ª–∞–≤–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π —É—Å–ø–µ—Ö–∞)
            if comparison_files_after:
                file_time = comparison_files_after[0].stat().st_mtime
                current_time = datetime.now().timestamp()
                time_diff = current_time - file_time
                
                logger.info(f"[TESTING] –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω ({time_diff/60:.1f} –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥)")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                new_data = pd.read_csv(comparison_files_after[0])
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if existing_data is not None:
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –æ–±–Ω–æ–≤–∏–ª–∏
                    existing_data = existing_data[~existing_data['symbol'].isin(symbols_to_test)]
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                    self.single_results = pd.concat([existing_data, new_data], ignore_index=True)
                    logger.info(f"[TESTING] –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                else:
                    self.single_results = new_data
                    logger.info(f"[TESTING] –ó–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É (—Ñ–∞–π–ª –µ—Å—Ç—å)
                if result and result.returncode != 0:
                    logger.warning("[TESTING] –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏, –Ω–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
                    try:
                        if result.stderr:
                            stderr_safe = result.stderr[-500:].encode('ascii', 'replace').decode('ascii')
                            logger.debug(f"STDERR: {stderr_safe}")
                    except:
                        pass
            else:
                # –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω - —ç—Ç–æ –æ—à–∏–±–∫–∞
                logger.error("[TESTING] –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞")
                if result:
                    try:
                        if result.stderr:
                            stderr_safe = result.stderr[-500:].encode('ascii', 'replace').decode('ascii')
                            logger.error(f"STDERR: {stderr_safe}")
                    except:
                        pass
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                if existing_data is not None:
                    logger.warning("[TESTING] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–Ω–æ–≤—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã)")
                    self.single_results = existing_data
                    return True
                
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ 15m –∏ 1h –º–æ–¥–µ–ª–µ–π
            has_15m = self.single_results['model_filename'].str.contains('_15_|_15m', na=False).any()
            has_1h = self.single_results['model_filename'].str.contains('_60_|_1h', na=False).any()
            
            if not has_15m:
                logger.warning("[TESTING] ‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ 15m –º–æ–¥–µ–ª–µ–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
            if not has_1h:
                logger.warning("[TESTING] ‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ 1h –º–æ–¥–µ–ª–µ–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
            
            if has_15m and has_1h:
                logger.info("[TESTING] ‚úÖ –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∏ 15m, –∏ 1h –º–æ–¥–µ–ª–∏")
                logger.info(f"[TESTING] –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {len(self.single_results)}")
                return True
            else:
                logger.error("[TESTING] ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("[TESTING] –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏")
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            if existing_data is not None:
                logger.warning("[TESTING] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (—Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏)")
                self.single_results = existing_data
                return True
            return False
        except Exception as e:
            self.log_error("TESTING", "ALL", e)
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            if existing_data is not None:
                logger.warning("[TESTING] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏)")
                self.single_results = existing_data
                return True
            return False
    
    def calculate_composite_score(self, row: pd.Series) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç composite score –¥–ª—è –º–æ–¥–µ–ª–∏"""
        pnl = row.get('total_pnl_pct', 0)
        wr = row.get('win_rate_pct', row.get('win_rate', 0))
        pf = row.get('profit_factor', 0)
        sharpe = row.get('sharpe_ratio', 0)
        dd = row.get('max_drawdown_pct', 100)
        
        score = (
            pnl * 0.4 +
            wr * 0.2 +
            pf * 20.0 * 0.2 +
            sharpe * 0.1 +
            (100 - dd) * 0.1
        )
        return score
    
    def predict_mtf_combinations(self, symbol: str) -> pd.DataFrame:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
        –ù–µ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ MTF —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, —Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
        """
        logger.info(f"[PREDICTION] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è {symbol}")
        
        if self.single_results is None:
            logger.error("[PREDICTION] –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            return pd.DataFrame()
        
        symbol_data = self.single_results[self.single_results['symbol'] == symbol].copy()
        
        if symbol_data.empty:
            logger.warning(f"[PREDICTION] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} –≤ —Ñ–∞–π–ª–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            logger.info(f"[PREDICTION] –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python compare_ml_models.py --symbols {symbol} --days {self.days}")
            return pd.DataFrame()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ 1h –∏ 15m –º–æ–¥–µ–ª–∏
        models_1h = symbol_data[
            (symbol_data['mode_suffix'] == '1h') |
            (symbol_data['model_filename'].str.contains('_60_|_1h', na=False))
        ].copy()
        
        models_15m = symbol_data[
            (symbol_data['mode_suffix'] == '15m') |
            (symbol_data['model_filename'].str.contains('_15_|_15m', na=False))
        ].copy()
        
        if models_1h.empty or models_15m.empty:
            logger.warning(f"[PREDICTION] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {symbol}")
            logger.info(f"  1h –º–æ–¥–µ–ª–µ–π: {len(models_1h)}, 15m –º–æ–¥–µ–ª–µ–π: {len(models_15m)}")
            return pd.DataFrame()
        
        # –í—ã—á–∏—Å–ª—è–µ–º composite score –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        models_1h['composite_score'] = models_1h.apply(self.calculate_composite_score, axis=1)
        models_15m['composite_score'] = models_15m.apply(self.calculate_composite_score, axis=1)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        models_1h = models_1h.sort_values('composite_score', ascending=False)
        models_15m = models_15m.sort_values('composite_score', ascending=False)
        
        logger.info(f"[PREDICTION] {symbol}: –ù–∞–π–¥–µ–Ω–æ {len(models_1h)} 1h –º–æ–¥–µ–ª–µ–π, {len(models_15m)} 15m –º–æ–¥–µ–ª–µ–π")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        predictions = []
        
        for _, row_1h in models_1h.iterrows():
            for _, row_15m in models_15m.iterrows():
                model_1h_name = row_1h['model_filename'].replace('.pkl', '')
                model_15m_name = row_15m['model_filename'].replace('.pkl', '')
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                
                # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ
                predicted_pnl_avg = (row_1h['total_pnl_pct'] + row_15m['total_pnl_pct']) / 2
                predicted_wr_avg = (row_1h.get('win_rate_pct', 0) + row_15m.get('win_rate_pct', 0)) / 2
                
                # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ (1h –≤–∞–∂–Ω–µ–µ –¥–ª—è —Ç—Ä–µ–Ω–¥–∞, 15m –¥–ª—è –≤—Ö–æ–¥–∞)
                predicted_pnl_weighted = row_1h['total_pnl_pct'] * 0.4 + row_15m['total_pnl_pct'] * 0.6
                predicted_wr_weighted = (row_1h.get('win_rate_pct', 0) * 0.3 + 
                                        row_15m.get('win_rate_pct', 0) * 0.7)
                
                # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞ —Å—á–µ—Ç —Å–∏–Ω–µ—Ä–≥–∏–∏ (–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
                # MTF –æ–±—ã—á–Ω–æ –¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 20-50% –æ—Ç —Å—É–º–º—ã –æ–¥–∏–Ω–æ—á–Ω—ã—Ö
                synergy_factor = 1.3  # 30% —É–ª—É—á—à–µ–Ω–∏–µ –∑–∞ —Å—á–µ—Ç —Å–∏–Ω–µ—Ä–≥–∏–∏
                predicted_pnl_synergy = (row_1h['total_pnl_pct'] + row_15m['total_pnl_pct']) * synergy_factor / 2
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                predicted_pnl = predicted_pnl_weighted
                predicted_wr = predicted_wr_weighted
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π composite score
                predicted_score_1h = row_1h['composite_score']
                predicted_score_15m = row_15m['composite_score']
                predicted_score = (predicted_score_1h + predicted_score_15m) / 2
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                predicted_pf = (row_1h['profit_factor'] + row_15m['profit_factor']) / 2
                predicted_sharpe = (row_1h['sharpe_ratio'] + row_15m['sharpe_ratio']) / 2
                predicted_dd = max(row_1h.get('max_drawdown_pct', 100), row_15m.get('max_drawdown_pct', 100))
                
                predictions.append({
                    'model_1h': model_1h_name,
                    'model_15m': model_15m_name,
                    'symbol': symbol,
                    # –û–¥–∏–Ω–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    'single_1h_pnl': row_1h['total_pnl_pct'],
                    'single_15m_pnl': row_15m['total_pnl_pct'],
                    'single_1h_wr': row_1h.get('win_rate_pct', 0),
                    'single_15m_wr': row_15m.get('win_rate_pct', 0),
                    'single_1h_score': predicted_score_1h,
                    'single_15m_score': predicted_score_15m,
                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ MTF –º–µ—Ç—Ä–∏–∫–∏
                    'predicted_pnl_pct': predicted_pnl,
                    'predicted_wr': predicted_wr,
                    'predicted_pnl_avg': predicted_pnl_avg,
                    'predicted_pnl_synergy': predicted_pnl_synergy,
                    'predicted_score': predicted_score,
                    'predicted_profit_factor': predicted_pf,
                    'predicted_sharpe': predicted_sharpe,
                    'predicted_max_drawdown_pct': predicted_dd,
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    'single_1h_trades': row_1h.get('total_trades', 0),
                    'single_15m_trades': row_15m.get('total_trades', 0),
                    'estimated_mtf_trades': min(row_1h.get('total_trades', 0), row_15m.get('total_trades', 0)) * 0.8,
                })
        
        if not predictions:
            logger.warning(f"[PREDICTION] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {symbol}")
            return pd.DataFrame()
        
        df_predictions = pd.DataFrame(predictions)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ predicted_score
        df_predictions = df_predictions.sort_values('predicted_score', ascending=False)
        
        logger.info(f"[PREDICTION] {symbol}: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df_predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        logger.info(f"[PREDICTION] {symbol}: –õ—É—á—à–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è:")
        best = df_predictions.iloc[0]
        logger.info(f"   {best['model_1h']} + {best['model_15m']}")
        logger.info(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π PnL: {best['predicted_pnl_pct']:.2f}%")
        logger.info(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π WR: {best['predicted_wr']:.1f}%")
        logger.info(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π Score: {best['predicted_score']:.2f}")
        
        return df_predictions
    
    def select_best_combinations(self, symbol: str, df_predictions: pd.DataFrame) -> Dict[str, Any]:
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        if df_predictions.empty:
            return {}
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø-N –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
        top_combinations = df_predictions.head(self.top_n).copy()
        
        best = top_combinations.iloc[0]
        
        result = {
            "symbol": symbol,
            "best_combination": {
                "model_1h": best['model_1h'],
                "model_15m": best['model_15m'],
                "predicted_pnl_pct": best['predicted_pnl_pct'],
                "predicted_wr": best['predicted_wr'],
                "predicted_score": best['predicted_score'],
                "predicted_profit_factor": best['predicted_profit_factor'],
                "predicted_sharpe": best['predicted_sharpe'],
                "predicted_max_drawdown_pct": best['predicted_max_drawdown_pct'],
            },
            "single_models_performance": {
                "1h": {
                    "model": best['model_1h'],
                    "pnl": best['single_1h_pnl'],
                    "wr": best['single_1h_wr'],
                    "score": best['single_1h_score'],
                },
                "15m": {
                    "model": best['model_15m'],
                    "pnl": best['single_15m_pnl'],
                    "wr": best['single_15m_wr'],
                    "score": best['single_15m_score'],
                }
            },
            "top_combinations": top_combinations.to_dict('records'),
        }
        
        return result
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        for symbol, df_pred in self.predictions.items():
            if not df_pred.empty:
                filename = self.output_dir / f"predicted_mtf_{symbol}_{self.timestamp}.csv"
                df_pred.to_csv(filename, index=False)
                logger.info(f"[SAVE] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {symbol} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        output_data = {
            "timestamp": datetime.now().isoformat(),
            "prediction_version": "1.0",
            "backtest_days": self.days,
            "top_n": self.top_n,
            "method": "prediction_from_single_models",
            "note": "–≠—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö, –∞ –Ω–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ MTF",
            "best_combinations": self.best_combinations,
        }
        
        filename = self.output_dir / f"best_predicted_mtf_{self.timestamp}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"[SAVE] –õ—É—á—à–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
        return filename
    
    def print_summary(self):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\n" + "=" * 100)
        print("üìä –°–í–û–î–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô MTF –ö–û–ú–ë–ò–ù–ê–¶–ò–ô")
        print("=" * 100)
        print()
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö, –∞ –Ω–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ MTF")
        print("   –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ø-–∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ")
        print()
        
        symbols_with_results = [s for s in self.symbols if s in self.best_combinations]
        symbols_without_results = [s for s in self.symbols if s not in self.best_combinations]
        
        if symbols_without_results:
            print(f"\n‚ö†Ô∏è  –°–∏–º–≤–æ–ª—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö: {', '.join(symbols_without_results)}")
            print("   –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
            print(f"   python compare_ml_models.py --symbols {','.join(symbols_without_results)} --days {self.days}")
            print()
        
        for symbol in symbols_with_results:
            best = self.best_combinations[symbol]
            combo = best['best_combination']
            single = best['single_models_performance']
            
            print(f"üéØ {symbol}")
            print("-" * 100)
            print(f"–õ—É—á—à–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è:")
            print(f"  1h: {combo['model_1h']}")
            print(f"     –û–¥–∏–Ω–æ—á–Ω—ã–π PnL: {single['1h']['pnl']:.2f}%, WR: {single['1h']['wr']:.1f}%")
            print(f"  15m: {combo['model_15m']}")
            print(f"     –û–¥–∏–Ω–æ—á–Ω—ã–π PnL: {single['15m']['pnl']:.2f}%, WR: {single['15m']['wr']:.1f}%")
            print()
            print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ MTF –º–µ—Ç—Ä–∏–∫–∏:")
            print(f"  PnL: {combo['predicted_pnl_pct']:.2f}%")
            print(f"  Win Rate: {combo['predicted_wr']:.1f}%")
            print(f"  Profit Factor: {combo['predicted_profit_factor']:.2f}")
            print(f"  Sharpe Ratio: {combo['predicted_sharpe']:.2f}")
            print(f"  Max Drawdown: {combo['predicted_max_drawdown_pct']:.2f}%")
            print(f"  Composite Score: {combo['predicted_score']:.2f}")
            print()
        
        print("=" * 100)
        print()
    
    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        start_time = datetime.now()
        logger.info("=" * 100)
        logger.info("üöÄ –ù–ê–ß–ê–õ–û –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø MTF –ö–û–ú–ë–ò–ù–ê–¶–ò–ô")
        logger.info("=" * 100)
        logger.info(f"–°–∏–º–≤–æ–ª—ã: {', '.join(self.symbols)}")
        logger.info(f"–î–Ω–∏ –±—ç–∫—Ç–µ—Å—Ç–∞: {self.days}")
        logger.info(f"–¢–æ–ø-N –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {self.top_n}")
        logger.info("=" * 100)
        
        # –≠—Ç–∞–ø 1: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        logger.info("\n[–≠–¢–ê–ü 1] –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–î–ò–ù–û–ß–ù–´–• –ú–û–î–ï–õ–ï–ô")
        logger.info("-" * 100)
        success = self.test_single_models()
        if not success:
            logger.error("[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏")
            return None
        
        # –≠—Ç–∞–ø 2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
        logger.info("\n[–≠–¢–ê–ü 2] –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï MTF –ö–û–ú–ë–ò–ù–ê–¶–ò–ô")
        logger.info("-" * 100)
        
        symbols_without_data = []
        for symbol in self.symbols:
            df_pred = self.predict_mtf_combinations(symbol)
            self.predictions[symbol] = df_pred
            
            if not df_pred.empty:
                best_combo = self.select_best_combinations(symbol, df_pred)
                if best_combo:
                    self.best_combinations[symbol] = best_combo
            else:
                symbols_without_data.append(symbol)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏–º–≤–æ–ª—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö - —Å–æ–±–∏—Ä–∞–µ–º –∏—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if symbols_without_data and not self.skip_testing:
            logger.info(f"\n[–ê–í–¢–û–°–ë–û–†] –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–∏–º–≤–æ–ª—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö: {', '.join(symbols_without_data)}")
            logger.info("[–ê–í–¢–û–°–ë–û–†] –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö...")
            
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            try:
                cmd = [
                    self.python_exe,
                    "compare_ml_models.py",
                    "--symbols", ",".join(symbols_without_data),
                    "--days", str(self.days),
                    "--output", "csv",
                    "--interval", "15m",
                    "--detailed-analysis"
                ]
                
                logger.info(f"[–ê–í–¢–û–°–ë–û–†] –ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=7200
                )
                
                # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
                process_start_time = datetime.now().timestamp()
                
                # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ, —á—Ç–æ–±—ã —Ñ–∞–π–ª —É—Å–ø–µ–ª —Å–æ–∑–¥–∞—Ç—å—Å—è
                import time
                time.sleep(2)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–∑–¥–∞–Ω –ª–∏ –Ω–æ–≤—ã–π —Ñ–∞–π–ª (—Å–æ–∑–¥–∞–Ω–Ω—ã–π –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞)
                comparison_files_after = sorted(
                    Path(".").glob("ml_models_comparison_*.csv"),
                    key=lambda p: p.stat().st_mtime if p.exists() else 0,
                    reverse=True
                )
                
                # –ò—â–µ–º —Ñ–∞–π–ª, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
                new_file = None
                for file_path in comparison_files_after:
                    file_time = file_path.stat().st_mtime
                    # –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω –Ω–µ –±–æ–ª–µ–µ —á–µ–º –∑–∞ 5 —Å–µ–∫—É–Ω–¥ –¥–æ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
                    # (—Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–ø—É—Å–∫)
                    if file_time >= (process_start_time - 5):
                        new_file = file_path
                        break
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–æ–≤—ã–π —Ñ–∞–π–ª, –±–µ—Ä–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π
                if new_file is None and comparison_files_after:
                    new_file = comparison_files_after[0]
                    logger.warning(f"[–ê–í–¢–û–°–ë–û–†] –ù–µ –Ω–∞–π–¥–µ–Ω —è–≤–Ω–æ –Ω–æ–≤—ã–π —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π: {new_file}")
                
                if new_file and new_file.exists():
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                    new_data = pd.read_csv(new_file)
                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {new_file} (—Å–æ–∑–¥–∞–Ω {datetime.fromtimestamp(new_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')})")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –µ—Å—Ç—å –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    new_symbols = set(new_data['symbol'].unique()) if 'symbol' in new_data.columns else set()
                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] –í –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω—ã —Å–∏–º–≤–æ–ª—ã: {', '.join(sorted(new_symbols))}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω—É–∂–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                    missing_in_new = set(symbols_without_data) - new_symbols
                    if missing_in_new:
                        logger.warning(f"[–ê–í–¢–û–°–ë–û–†] –í –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {', '.join(missing_in_new)}")
                        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–∞—Ö
                        logger.info("[–ê–í–¢–û–°–ë–û–†] –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–∞—Ö...")
                        for file_path in comparison_files_after[1:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ 4 —Ñ–∞–π–ª–∞
                            try:
                                check_data = pd.read_csv(file_path)
                                check_symbols = set(check_data['symbol'].unique()) if 'symbol' in check_data.columns else set()
                                found_missing = set(missing_in_new) & check_symbols
                                if found_missing:
                                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] –ù–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {', '.join(found_missing)} –≤ —Ñ–∞–π–ª–µ {file_path}")
                                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                                    found_data = check_data[check_data['symbol'].isin(found_missing)]
                                    new_data = pd.concat([new_data, found_data], ignore_index=True)
                                    new_symbols.update(found_missing)
                                    missing_in_new -= found_missing
                            except Exception as e:
                                logger.debug(f"[–ê–í–¢–û–°–ë–û–†] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {file_path}: {e}")
                        
                        if missing_in_new:
                            logger.warning(f"[–ê–í–¢–û–°–ë–û–†] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è: {', '.join(missing_in_new)}")
                        else:
                            logger.info("[–ê–í–¢–û–°–ë–û–†] –í—Å–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–∞—Ö")
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏
                    if self.single_results is not None:
                        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                        self.single_results = self.single_results[
                            ~self.single_results['symbol'].isin(symbols_without_data)
                        ]
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                        self.single_results = pd.concat([self.single_results, new_data], ignore_index=True)
                    else:
                        self.single_results = new_data
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                    final_symbols = set(self.single_results['symbol'].unique()) if 'symbol' in self.single_results.columns else set()
                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] –î–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã: {len(self.single_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] –ò—Ç–æ–≥–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –¥–∞–Ω–Ω—ã—Ö: {', '.join(sorted(final_symbols))}")
                    
                    # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —ç—Ç–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    logger.info("[–ê–í–¢–û–°–ë–û–†] –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤...")
                    for symbol in symbols_without_data:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
                        if symbol in final_symbols:
                            df_pred = self.predict_mtf_combinations(symbol)
                            self.predictions[symbol] = df_pred
                            
                            if not df_pred.empty:
                                best_combo = self.select_best_combinations(symbol, df_pred)
                                if best_combo:
                                    self.best_combinations[symbol] = best_combo
                                    logger.info(f"[–ê–í–¢–û–°–ë–û–†] ‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –¥–ª—è {symbol}")
                            else:
                                logger.warning(f"[–ê–í–¢–û–°–ë–û–†] ‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –µ—Å—Ç—å, –Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π 15m –∏–ª–∏ 1h)")
                        else:
                            logger.warning(f"[–ê–í–¢–û–°–ë–û–†] ‚ö†Ô∏è  –°–∏–º–≤–æ–ª {symbol} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∏—Ç–æ–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                else:
                    logger.warning(f"[–ê–í–¢–û–°–ë–û–†] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {', '.join(symbols_without_data)}")
                    
            except Exception as e:
                logger.error(f"[–ê–í–¢–û–°–ë–û–†] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
                self.log_error("AUTO_COLLECT", ",".join(symbols_without_data), e)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        logger.info("\n[–°–û–•–†–ê–ù–ï–ù–ò–ï] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        result_file = self.save_results()
        
        # –ü–µ—á–∞—Ç—å —Å–≤–æ–¥–∫–∏
        self.print_summary()
        
        # –û—Ç—á–µ—Ç
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() / 60  # –º–∏–Ω—É—Ç—ã
        
        logger.info("\n" + "=" * 100)
        logger.info("‚úÖ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        logger.info("=" * 100)
        logger.info(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} –º–∏–Ω—É—Ç")
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(self.symbols)}")
        logger.info(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {sum(len(df) for df in self.predictions.values())}")
        logger.info(f"–í—ã–±—Ä–∞–Ω–æ –ª—É—á—à–∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {len(self.best_combinations)}")
        logger.info(f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {result_file}")
        logger.info("=" * 100)
        
        return result_file


def main():
    parser = argparse.ArgumentParser(
        description="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–∏—Ö MTF –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("--symbols", type=str, default=None,
                       help="–°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ state.active_symbols)")
    parser.add_argument("--days", type=int, default=30,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30)")
    parser.add_argument("--output-dir", type=str, default="mtf_predictions",
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--top-n", type=int, default=10,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)")
    parser.add_argument("--skip-testing", action="store_true",
                       help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã
    if args.symbols:
        symbols = [s.strip().upper() for s in args.symbols.split(",")]
    else:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ state
        state = BotState()
        symbols = state.active_symbols
        if not symbols:
            symbols = ["BTCUSDT"]  # Fallback
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å
    predictor = MTFPredictor(
        symbols=symbols,
        days=args.days,
        output_dir=args.output_dir,
        top_n=args.top_n,
        skip_testing=args.skip_testing,
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    try:
        predictor.run()
    except KeyboardInterrupt:
        logger.info("\n[WARN] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"[ERROR] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
