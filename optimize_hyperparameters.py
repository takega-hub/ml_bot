"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Grid Search.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python optimize_hyperparameters.py --model rf_BTCUSDT_15_mtf --symbol BTCUSDT
"""

import argparse
import sys
from pathlib import Path
from typing import Dict, Any, List, Tuple
import json
from datetime import datetime

import pandas as pd
import numpy as np
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent))

from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer
from bot.config import load_settings


def optimize_rf_hyperparameters(
    X: np.ndarray,
    y: np.ndarray,
    param_grid: Dict[str, List[Any]] = None
) -> Dict[str, Any]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Random Forest."""
    if param_grid is None:
        param_grid = {
            'n_estimators': [50, 100, 150, 200],
            'max_depth': [8, 10, 12, 15, 20],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': ['balanced', 'balanced_subsample', None],
        }
    
    rf = RandomForestClassifier(random_state=42, n_jobs=-1)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º TimeSeriesSplit –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    tscv = TimeSeriesSplit(n_splits=3)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º f1_macro –¥–ª—è –ª—É—á—à–µ–π –æ—Ü–µ–Ω–∫–∏ –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    grid_search = GridSearchCV(
        rf,
        param_grid,
        cv=tscv,
        scoring='f1_macro',  # –õ—É—á—à–µ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X, y)
    
    return {
        'best_params': grid_search.best_params_,
        'best_score': grid_search.best_score_,
        'best_estimator': grid_search.best_estimator_
    }


def optimize_xgb_hyperparameters(
    X: np.ndarray,
    y: np.ndarray,
    param_grid: Dict[str, List[Any]] = None
) -> Dict[str, Any]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ XGBoost."""
    if param_grid is None:
        param_grid = {
            'n_estimators': [50, 100, 150, 200],
            'max_depth': [4, 6, 8, 10],
            'learning_rate': [0.05, 0.1, 0.15, 0.2],
            'subsample': [0.8, 0.9, 1.0],
            'colsample_bytree': [0.8, 0.9, 1.0],
            'min_child_weight': [1, 3, 5],
            'gamma': [0, 0.1, 0.2],
        }
    
    xgb_model = xgb.XGBClassifier(random_state=42, n_jobs=-1)
    
    tscv = TimeSeriesSplit(n_splits=3)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º f1_macro –¥–ª—è –ª—É—á—à–µ–π –æ—Ü–µ–Ω–∫–∏ –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    grid_search = GridSearchCV(
        xgb_model,
        param_grid,
        cv=tscv,
        scoring='f1_macro',  # –õ—É—á—à–µ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X, y)
    
    return {
        'best_params': grid_search.best_params_,
        'best_score': grid_search.best_score_,
        'best_estimator': grid_search.best_estimator_
    }


def optimize_lgb_hyperparameters(
    X: np.ndarray,
    y: np.ndarray,
    param_grid: Dict[str, List[Any]] = None
) -> Dict[str, Any]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LightGBM."""
    if param_grid is None:
        param_grid = {
            'n_estimators': [50, 100, 150, 200],
            'max_depth': [4, 6, 8, 10],
            'learning_rate': [0.05, 0.1, 0.15, 0.2],
            'num_leaves': [31, 50, 70, 100],
            'subsample': [0.8, 0.9, 1.0],
            'min_child_samples': [20, 30, 50],
            'reg_alpha': [0, 0.1, 0.5],
            'reg_lambda': [0, 0.1, 0.5],
        }
    
    lgb_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)
    
    tscv = TimeSeriesSplit(n_splits=3)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º f1_macro –¥–ª—è –ª—É—á—à–µ–π –æ—Ü–µ–Ω–∫–∏ –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    grid_search = GridSearchCV(
        lgb_model,
        param_grid,
        cv=tscv,
        scoring='f1_macro',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X, y)
    
    return {
        'best_params': grid_search.best_params_,
        'best_score': grid_search.best_score_,
        'best_estimator': grid_search.best_estimator_
    }


def main():
    parser = argparse.ArgumentParser(description='Optimize hyperparameters for ML models')
    parser.add_argument('--model', type=str, required=True,
                       help='Model type: rf, xgb, lgb')
    parser.add_argument('--symbol', type=str, default=None,
                       help='Symbol (e.g., BTCUSDT). If not specified, optimizes for all symbols')
    parser.add_argument('--symbols', type=str, default=None,
                       help='Comma-separated list of symbols (e.g., BTCUSDT,ETHUSDT,SOLUSDT)')
    parser.add_argument('--interval', type=str, default='15',
                       help='Interval (default: 15)')
    parser.add_argument('--mtf', action='store_true',
                       help='Use MTF features')
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
    if args.symbols:
        symbols = [s.strip().upper() for s in args.symbols.split(',')]
    elif args.symbol:
        symbols = [args.symbol.upper()]
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ 6 —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä
        symbols = ["SOLUSDT", "BTCUSDT", "ETHUSDT", "XRPUSDT", "ADAUSDT", "BNBUSDT"]
    
    print("=" * 80)
    print("üîß –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í")
    print("=" * 80)
    print(f"–ú–æ–¥–µ–ª—å: {args.model}")
    print(f"–°–∏–º–≤–æ–ª—ã: {', '.join(symbols)} ({len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤)")
    print(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª: {args.interval}")
    print(f"MTF: {args.mtf}")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = load_settings()
    
    all_results = []
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
        print("\n" + "=" * 80)
        print(f"üìä –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø {symbol}")
        print("=" * 80)
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("\nüì• –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö...")
        collector = DataCollector(settings.api)
        df_raw = collector.collect_klines(
            symbol=symbol,
            interval=args.interval,
            start_date=None,
            end_date=None,
            limit=5000,
            save_to_file=False,
        )
        
        if df_raw.empty:
            print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
        
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw)} —Å–≤–µ—á–µ–π")
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏
        print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π...")
        feature_engineer = FeatureEngineer()
        df_features = feature_engineer.create_technical_indicators(df_raw)
        
        # MTF —Ñ–∏—á–∏
        if args.mtf:
            print("   –î–æ–±–∞–≤–ª–µ–Ω–∏–µ MTF —Ñ–∏—á–µ–π...")
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã—Å—à–∏—Ö –¢–§
            df_1h = collector.collect_klines(
                symbol=symbol,
                interval="60",
                start_date=None,
                end_date=None,
                limit=2000,
                save_to_file=False,
            )
            df_4h = collector.collect_klines(
                symbol=symbol,
                interval="240",
                start_date=None,
                end_date=None,
                limit=1000,
                save_to_file=False,
            )
            
            higher_timeframes = {}
            if not df_1h.empty:
                higher_timeframes["60"] = df_1h
            if not df_4h.empty:
                higher_timeframes["240"] = df_4h
            
            if higher_timeframes:
                df_features = feature_engineer.add_mtf_features(df_features, higher_timeframes)
        
        # –°–æ–∑–¥–∞–µ–º target
        print("\nüéØ –°–æ–∑–¥–∞–Ω–∏–µ target variable...")
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=5,
            threshold_pct=0.5,
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=1.5,
            max_hold_periods=96,
            min_profit_pct=0.5,
            use_adaptive_params=True,
        )
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        print(f"   X shape: {X.shape}, y shape: {y.shape}")
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(y + 1)}")  # +1 –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        print(f"\nüîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {args.model}...")
        
        try:
            if args.model == 'rf':
                results = optimize_rf_hyperparameters(X, y)
            elif args.model == 'xgb':
                results = optimize_xgb_hyperparameters(X, y)
            elif args.model == 'lgb':
                results = optimize_lgb_hyperparameters(X, y)
            else:
                print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {args.model}")
                continue
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            result_dict = {
                'model': args.model,
                'symbol': symbol,
                'interval': args.interval,
                'mtf': args.mtf,
                'best_params': results['best_params'],
                'best_score': float(results['best_score']),
                'timestamp': datetime.now().isoformat(),
            }
            
            all_results.append(result_dict)
            
            print(f"\n‚úÖ {symbol} - –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
            for param, value in results['best_params'].items():
                print(f"   {param}: {value}")
            print(f"   –õ—É—á—à–∏–π score: {results['best_score']:.4f}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {symbol}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
    if all_results:
        output_file = f"hyperparams_{args.model}_all_{args.interval}{'_mtf' if args.mtf else ''}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 80)
        print("‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –î–õ–Ø –í–°–ï–• –°–ò–ú–í–û–õ–û–í")
        print("=" * 80)
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(all_results)}/{len(symbols)}")
        print(f"\nüíæ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        print("\nüìä –°–í–û–î–ö–ê:")
        for result in all_results:
            print(f"   {result['symbol']}: score = {result['best_score']:.4f}")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª")


if __name__ == "__main__":
    main()
