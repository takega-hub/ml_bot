"""
ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é ML-–º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.
"""
import warnings
import os

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è scikit-learn –î–û –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –ü–ï–†–í–û–ô
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
os.environ['SKLEARN_WARNINGS'] = 'ignore'

# –§–∏–ª—å—Ç—Ä—É–µ–º –≤—Å–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è sklearn
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', module='sklearn')
warnings.filterwarnings('ignore', message='.*sklearn.*')
warnings.filterwarnings('ignore', message='.*parallel.*')
warnings.filterwarnings('ignore', message='.*delayed.*')
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.*')
warnings.filterwarnings('ignore', message='.*should be used with.*')
warnings.filterwarnings('ignore', message='.*propagate the scikit-learn configuration.*')
# –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.delayed.*')
# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è XGBoost –ø—Ä–æ pickle –∏ –≤–µ—Ä—Å–∏–∏
warnings.filterwarnings('ignore', message='.*loading a serialized model.*')
warnings.filterwarnings('ignore', message='.*XGBoost.*')
os.environ['XGB_SILENT'] = '1'
os.environ['PYTHONWARNINGS'] = 'ignore'

import pickle
import logging
from pathlib import Path
from typing import Optional, Dict, Any

import numpy as np
import pandas as pd

from bot.strategy import Action, Bias, Signal
from bot.ml.feature_engineering import FeatureEngineer
from bot.config import StrategyParams
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –∞–Ω—Å–∞–º–±–ª—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pickle
from bot.ml.model_trainer import PreTrainedVotingEnsemble, WeightedEnsemble, TripleEnsemble

logger = logging.getLogger(__name__)


class MLStrategy:
    """
    ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã.
    """
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.5, min_signal_strength: str = "—Å–ª–∞–±–æ–µ", stability_filter: bool = True, use_dynamic_threshold: bool = True, min_signals_per_day: int = 1, max_signals_per_day: int = 10):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—é.
        
        Args:
            model_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pkl —Ñ–∞–π–ª)
            confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏ (0-1)
            min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ ("—Å–ª–∞–±–æ–µ", "—É–º–µ—Ä–µ–Ω–Ω–æ–µ", "—Å—Ä–µ–¥–Ω–µ–µ", "—Å–∏–ª—å–Ω–æ–µ", "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ")
            stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            use_dynamic_threshold: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            min_signals_per_day: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Ö–æ—Ç—è –±—ã 1 —Å–∏–≥–Ω–∞–ª)
            max_signals_per_day: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∏–∑–±—ã—Ç–æ—á–Ω—É—é —Ç–æ—Ä–≥–æ–≤–ª—é)
        """
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.min_signal_strength = min_signal_strength
        self.stability_filter = stability_filter
        self.use_dynamic_threshold = use_dynamic_threshold
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞
        strength_thresholds = {
            "—Å–ª–∞–±–æ–µ": 0.0,
            "—É–º–µ—Ä–µ–Ω–Ω–æ–µ": 0.6,
            "—Å—Ä–µ–¥–Ω–µ–µ": 0.7,
            "—Å–∏–ª—å–Ω–æ–µ": 0.8,
            "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ": 0.9
        }
        self.min_strength_threshold = strength_thresholds.get(min_signal_strength, 0.6)
        
        # –ò—Å—Ç–æ—Ä–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
        self.confidence_history = []
        self.max_history_size = 100
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        # –•—Ä–∞–Ω–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–∏–≥–Ω–∞–ª–æ–≤: [(timestamp, action, confidence), ...]
        self.signal_history = []
        self.max_signal_history = 20  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–∏–≥–Ω–∞–ª–æ–≤
        self.min_bars_between_opposite_signals = 4  # –ú–∏–Ω–∏–º—É–º –±–∞—Ä–æ–≤ –º–µ–∂–¥—É –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
        self.min_confidence_difference = 0.15  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É LONG –∏ SHORT (15%)
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        # –•—Ä–∞–Ω–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –¥–∞—Ç–∞–º: {date_str: count}
        self.daily_signals_count = {}
        self.min_signals_per_day = min_signals_per_day
        self.max_signals_per_day = max_signals_per_day
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.model_data = self._load_model()
        if "model" not in self.model_data:
            raise KeyError(f"Model data is missing 'model' key. Available keys: {list(self.model_data.keys())}")
        self.model = self.model_data["model"]
        self.scaler = self.model_data["scaler"]
        self.feature_names = self.model_data["feature_names"]
        self.is_ensemble = self.model_data.get("metadata", {}).get("model_type", "").startswith("ensemble")
        
        # –ï—Å–ª–∏ —ç—Ç–æ QuadEnsemble, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º feature_names –≤ lstm_trainer
        if hasattr(self.model, 'lstm_trainer') and self.model.lstm_trainer is not None:
            # –ï—Å–ª–∏ feature_names –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ lstm_trainer, –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
            if not hasattr(self.model.lstm_trainer, 'feature_names') or self.model.lstm_trainer.feature_names is None:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ scaler (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π)
                if hasattr(self.model.lstm_trainer, 'scaler') and self.model.lstm_trainer.scaler is not None:
                    expected_features = self.model.lstm_trainer.scaler.n_features_in_ if hasattr(self.model.lstm_trainer.scaler, 'n_features_in_') else None
                    if expected_features and self.feature_names:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ expected_features —Ñ–∏—á–µ–π (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LSTM)
                        # LSTM –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä–≤—ã–µ N —Ñ–∏—á–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 50)
                        self.model.lstm_trainer.feature_names = self.feature_names[:expected_features]
                        if not hasattr(self, '_lstm_feature_names_restored'):
                            logger.debug(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features")
                            self._lstm_feature_names_restored = True
                    elif self.feature_names:
                        # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ scaler, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ feature_names
                        self.model.lstm_trainer.feature_names = self.feature_names
                        if not hasattr(self, '_lstm_feature_names_restored'):
                            logger.debug(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features (from all features)")
                            self._lstm_feature_names_restored = True
                elif self.feature_names:
                    # –ï—Å–ª–∏ scaler –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ feature_names
                    self.model.lstm_trainer.feature_names = self.feature_names
                    if not hasattr(self, '_lstm_feature_names_restored'):
                        logger.debug(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features (scaler unavailable)")
                        self._lstm_feature_names_restored = True
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º feature engineer
        self.feature_engineer = FeatureEngineer()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        model_filename = Path(model_path).name
        symbol_from_model = "UNKNOWN"
        if "_" in model_filename:
            parts = model_filename.replace(".pkl", "").split("_")
            # –§–æ—Ä–º–∞—Ç—ã:
            # - rf_ETHUSDT_15_15m.pkl -> ["rf","ETHUSDT","15","15m"]
            # - ensemble_BTCUSDT_15_mtf.pkl -> ["ensemble","BTCUSDT","15","mtf"]
            # - triple_ensemble_BTCUSDT_15_15m.pkl -> ["triple","ensemble","BTCUSDT","15","15m"]
            # - quad_ensemble_BTCUSDT_15_mtf.pkl -> ["quad","ensemble","BTCUSDT","15","mtf"]
            if len(parts) >= 3 and parts[0] in ("triple", "quad") and parts[1] == "ensemble":
                symbol_from_model = parts[2]
            elif len(parts) >= 2:
                symbol_from_model = parts[1]
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        model_metadata = self.model_data.get("metadata", {})
        model_type_str = model_metadata.get("model_type", "unknown")
        if "ensemble" in model_type_str.lower():
            self.is_ensemble = True
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –ª–æ–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ)
        if not hasattr(self, '_model_loaded_logged'):
            model_type = 'üéØ ENSEMBLE' if self.is_ensemble else 'Single'
            cv_acc = self.model_data.get("metrics", {}).get('cv_mean', 0) if self.is_ensemble else 0
            logger.info(f"[ml] {symbol_from_model}: {model_type} (CV:{cv_acc:.3f}, conf:{confidence_threshold}, stab:{stability_filter})")
            self._model_loaded_logged = True
    
    def _load_model(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞."""
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        
        try:
            with open(self.model_path, "rb") as f:
                model_data = pickle.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
            if not isinstance(model_data, dict):
                raise TypeError(f"Expected dict from model file, got {type(model_data)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–ª—é—á–µ–π
            required_keys = ["model", "scaler", "feature_names"]
            missing_keys = [key for key in required_keys if key not in model_data]
            if missing_keys:
                raise KeyError(f"Missing required keys in model data: {missing_keys}. Available keys: {list(model_data.keys())}")
            
            return model_data
        except Exception as e:
            raise Exception(f"Failed to load model from {self.model_path}: {str(e)}") from e
    
    def prepare_features(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> np.ndarray:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ DataFrame –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∏—á–∏)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            –ú–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        # –ï—Å–ª–∏ —Ñ–∏—á–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã (skip_feature_creation=True), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
        if skip_feature_creation:
            df_with_features = df.copy()
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∑–∞–Ω–æ–≤–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ timestamp –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ (–Ω—É–∂–Ω–æ –¥–ª—è feature_engineer)
            df_work = df.copy()
            if "timestamp" in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                df_work = df_work.set_index("timestamp")
            elif "timestamp" not in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                if isinstance(df_work.index, pd.DatetimeIndex):
                    pass  # –£–∂–µ DatetimeIndex
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
                    df_work.index = pd.to_datetime(df_work.index, errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏—á–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            logger.debug(f"[ml_strategy] Preparing features: input DataFrame has {len(df_work)} rows")
            try:
                df_with_features = self.feature_engineer.create_technical_indicators(df_work)
                logger.debug(f"[ml_strategy] After create_technical_indicators: {len(df_with_features)} rows, {len(df_with_features.columns)} columns")
            except TypeError as e:
                if "'>' not supported" in str(e) or "NoneType" in str(e):
                    logger.error(f"[ml_strategy] ‚ùå ERROR: Comparison with None detected in create_technical_indicators")
                    logger.error(f"[ml_strategy]   Error: {e}")
                    logger.error(f"[ml_strategy]   Checking for None values in DataFrame...")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ None –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
                    for col in ["open", "high", "low", "close", "volume", "atr", "atr_pct", "rsi"]:
                        if col in df_work.columns:
                            none_count = df_work[col].isna().sum() + (df_work[col] == None).sum()
                            if none_count > 0:
                                logger.error(f"[ml_strategy]   Column '{col}' has {none_count} None/NaN values")
                    raise
                raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OHLCV)
        key_columns = ["open", "high", "low", "close", "volume"]
        if all(col in df_with_features.columns for col in key_columns):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            rows_before = len(df_with_features)
            df_with_features = df_with_features[df_with_features[key_columns].notna().any(axis=1)]
            rows_after = len(df_with_features)
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ò —ç—Ç–æ –Ω–µ skip_feature_creation (—á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ª–æ–≥–∏)
            if not skip_feature_creation and rows_before != rows_after:
                logger.debug(f"[ml_strategy] After filtering key columns: {rows_before} -> {rows_after} rows")
        else:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ skip_feature_creation
            if not skip_feature_creation:
                missing_key_cols = [col for col in key_columns if col not in df_with_features.columns]
                logger.warning(f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing key columns: {missing_key_cols}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        if len(df_with_features) == 0:
            logger.error(f"[ml_strategy] ‚ùå ERROR: No rows after filtering key columns")
            logger.error(f"[ml_strategy]   Input DataFrame shape: {df_work.shape}")
            logger.error(f"[ml_strategy]   After create_technical_indicators shape: {df_with_features.shape if 'df_with_features' in locals() else 'N/A'}")
            raise ValueError("No data available after creating features (all rows contain NaN in key columns)")
        
        # –í–ê–ñ–ù–û: –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Ñ–∏—á–∞—Ö –Ω—É–ª—è–º–∏ –ü–ï–†–ï–î –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –≤—ã—á–∏—Å–ª–∏–ª–∏—Å—å
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞—Ö (–Ω–æ –Ω–µ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö)
        feature_columns = [col for col in df_with_features.columns if col not in key_columns]
        if feature_columns:
            df_with_features[feature_columns] = df_with_features[feature_columns].fillna(0)
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏) NaN
        df_with_features = df_with_features.dropna(how='all')
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if len(df_with_features) == 0:
            raise ValueError("No data available after creating features (all rows contain NaN)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∏—á–µ–π
        missing_features = [f for f in self.feature_names if f not in df_with_features.columns]
        if missing_features:
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏
            if not hasattr(self, "_missing_features_warned"):
                logger.warning(
                    f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing {len(missing_features)} features: "
                    f"{missing_features[:10]}..."
                )
                logger.warning(
                    f"[ml_strategy]   Expected {len(self.feature_names)} features, "
                    f"got {len(df_with_features.columns)}"
                )
                self._missing_features_warned = True
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏ –Ω—É–ª—è–º–∏ –æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ DataFrame
            zeros_df = pd.DataFrame(
                0.0,
                index=df_with_features.index,
                columns=missing_features,
            )
            df_with_features = pd.concat([df_with_features, zeros_df], axis=1)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∏—á–∏ (–∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –Ω–µ –æ–∂–∏–¥–∞—é—Ç—Å—è –º–æ–¥–µ–ª—å—é)
        extra_features = [f for f in df_with_features.columns if f not in self.feature_names and f not in key_columns]
        # –£–±–∏—Ä–∞–µ–º –ª–æ–≥–∏ –æ –ª–∏—à–Ω–∏—Ö —Ñ–∏—á–∞—Ö - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è (–æ–Ω–∏ –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
        if extra_features:
            self._extra_features_warned = True  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, –Ω–æ –Ω–µ –ª–æ–≥–∏—Ä—É–µ–º
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        X = df_with_features[self.feature_names].values
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if len(X) == 0:
            raise ValueError("No data available after feature selection")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π —Å –º–æ–¥–µ–ª—å—é
        if X.shape[1] != len(self.feature_names):
            raise ValueError(f"Feature count mismatch: X has {X.shape[1]} features, but model expects {len(self.feature_names)}")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
        except ValueError as e:
            if "features" in str(e).lower() or "n_features" in str(e).lower():
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π
                scaler_expected = getattr(self.scaler, 'n_features_in_', None)
                if scaler_expected is None:
                    # –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è sklearn - –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ shape
                    try:
                        scaler_expected = self.scaler.mean_.shape[0] if hasattr(self.scaler, 'mean_') else None
                    except:
                        pass
                
                if scaler_expected and X.shape[1] != scaler_expected:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è)
                    if not hasattr(self, '_feature_mismatch_warned'):
                        self._feature_mismatch_warned = True
                    
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –±–æ–ª—å—à–µ —Ñ–∏—á–µ–π, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω—É–ª—è–º–∏
                    if X.shape[1] < scaler_expected:
                        missing_count = scaler_expected - X.shape[1]
                        if not hasattr(self, '_feature_adjustment_logged'):
                            self._feature_adjustment_logged = True
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                        zeros = np.zeros((X.shape[0], missing_count))
                        X = np.hstack([X, zeros])
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –º–µ–Ω—å—à–µ —Ñ–∏—á–µ–π, –æ–±—Ä–µ–∑–∞–µ–º
                    elif X.shape[1] > scaler_expected:
                        X = X[:, :scaler_expected]
                
                # –ü—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                try:
                    X_scaled = self.scaler.transform(X)
                except ValueError as e2:
                    logger.error(f"[ml_strategy] ‚ùå ERROR: Still cannot transform after adjustment")
                    logger.error(f"[ml_strategy]   Scaler expects: {scaler_expected} features")
                    logger.error(f"[ml_strategy]   X has: {X.shape[1]} features")
                    raise ValueError(f"Feature count mismatch: Scaler expects {scaler_expected} features, but got {X.shape[1]}. "
                                   f"Please retrain the model with the current feature set.") from e2
            else:
                raise
        
        return X_scaled
    
    def prepare_features_with_df(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> tuple[np.ndarray, pd.DataFrame]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ DataFrame –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ –º–∞—Å—Å–∏–≤, —Ç–∞–∫ –∏ DataFrame —Å —Ñ–∏—á–∞–º–∏.
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–º–æ–∂–µ—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∏—á–∏)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            (X_scaled, df_with_features) –≥–¥–µ:
            - X_scaled: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏
            - df_with_features: DataFrame —Å–æ –≤—Å–µ–º–∏ —Ñ–∏—á–∞–º–∏ (–¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ QuadEnsemble)
        """
        # –ï—Å–ª–∏ —Ñ–∏—á–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã (skip_feature_creation=True), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
        if skip_feature_creation:
            df_with_features = df.copy()
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∑–∞–Ω–æ–≤–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ timestamp –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ (–Ω—É–∂–Ω–æ –¥–ª—è feature_engineer)
            df_work = df.copy()
            if "timestamp" in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                df_work = df_work.set_index("timestamp")
            elif "timestamp" not in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                if isinstance(df_work.index, pd.DatetimeIndex):
                    pass  # –£–∂–µ DatetimeIndex
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
                    df_work.index = pd.to_datetime(df_work.index, errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏—á–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            if not skip_feature_creation:
                logger.debug(f"[ml_strategy] Preparing features: input DataFrame has {len(df_work)} rows")
            try:
                df_with_features = self.feature_engineer.create_technical_indicators(df_work)
                if not skip_feature_creation:
                    logger.debug(f"[ml_strategy] After create_technical_indicators: {len(df_with_features)} rows, {len(df_with_features.columns)} columns")
            except TypeError as e:
                if "'>' not supported" in str(e) or "NoneType" in str(e):
                    logger.error(f"[ml_strategy] ‚ùå ERROR: Comparison with None detected in create_technical_indicators")
                    logger.error(f"[ml_strategy]   Error: {e}")
                    raise
                raise

            # –î–æ–±–∞–≤–ª—è–µ–º MTF —Ñ–∏—á–∏, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            import os
            ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "0")
            ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")
            if ml_mtf_enabled and isinstance(df_work.index, pd.DatetimeIndex):
                try:
                    ohlcv_agg = {
                        "open": "first",
                        "high": "max",
                        "low": "min",
                        "close": "last",
                        "volume": "sum",
                    }
                    df_1h = df_work.resample("60min").agg(ohlcv_agg).dropna()
                    df_4h = df_work.resample("240min").agg(ohlcv_agg).dropna()
                    higher_timeframes = {}
                    if not df_1h.empty:
                        higher_timeframes["60"] = df_1h
                    if not df_4h.empty:
                        higher_timeframes["240"] = df_4h
                    if higher_timeframes:
                        df_with_features = self.feature_engineer.add_mtf_features(
                            df_with_features,
                            higher_timeframes,
                        )
                        logger.debug(f"[ml_strategy] MTF features enabled in prepare_features_with_df. Columns: {len(df_with_features.columns)}")
                except Exception as mtf_err:
                    logger.warning(f"[ml_strategy] Warning: failed to add MTF features in prepare_features_with_df: {mtf_err}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OHLCV)
        key_columns = ["open", "high", "low", "close", "volume"]
        if all(col in df_with_features.columns for col in key_columns):
            rows_before = len(df_with_features)
            df_with_features = df_with_features[df_with_features[key_columns].notna().any(axis=1)]
            rows_after = len(df_with_features)
        else:
            missing_key_cols = [col for col in key_columns if col not in df_with_features.columns]
            raise ValueError(f"Missing key columns: {missing_key_cols}")
        
        if len(df_with_features) == 0:
            raise ValueError("No data available after filtering key columns")
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Ñ–∏—á–∞—Ö
        feature_columns = [col for col in df_with_features.columns if col not in key_columns]
        if feature_columns:
            df_with_features[feature_columns] = df_with_features[feature_columns].ffill().bfill().fillna(0.0)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∏—á–µ–π
        missing_features = [f for f in self.feature_names if f not in df_with_features.columns]
        if missing_features:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏ –Ω—É–ª—è–º–∏
            zeros_df = pd.DataFrame(
                0.0,
                index=df_with_features.index,
                columns=missing_features,
            )
            df_with_features = pd.concat([df_with_features, zeros_df], axis=1)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        X = df_with_features[self.feature_names].values
        
        if len(X) == 0:
            raise ValueError("No data available after feature selection")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
        except ValueError as e:
            if "features" in str(e).lower() or "n_features" in str(e).lower():
                scaler_expected = getattr(self.scaler, 'n_features_in_', None)
                if scaler_expected is None:
                    try:
                        scaler_expected = self.scaler.mean_.shape[0] if hasattr(self.scaler, 'mean_') else None
                    except:
                        pass
                
                if scaler_expected and X.shape[1] != scaler_expected:
                    if X.shape[1] < scaler_expected:
                        missing_count = scaler_expected - X.shape[1]
                        zeros = np.zeros((X.shape[0], missing_count))
                        X = np.hstack([X, zeros])
                    elif X.shape[1] > scaler_expected:
                        X = X[:, :scaler_expected]
                    
                    X_scaled = self.scaler.transform(X)
                else:
                    raise
            else:
                raise
        
        return X_scaled, df_with_features
    
    def predict(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> tuple[int, float]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–∞—Ä–∞.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (OHLCV, —Ñ–∏—á–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–ª–∏ —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            (prediction, confidence) –≥–¥–µ:
            - prediction: 1 (LONG), -1 (SHORT), 0 (HOLD)
            - confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0-1)
        """
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ä
        if len(df) == 0:
            return 0, 0.0
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏ (—Å–æ–∑–¥–∞—Å—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ)
            # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏ X (–º–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π) –∏ df_with_features (DataFrame —Å —Ñ–∏—á–∞–º–∏) –¥–ª—è QuadEnsemble
            X, df_with_features = self.prepare_features_with_df(df, skip_feature_creation=skip_feature_creation)
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–∑–µ—Ü
            X_last = X[-1:].reshape(1, -1)
        except Exception as e:
            logger.error(f"[ml_strategy] Error preparing features: {e}")
            return 0, 0.0
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if hasattr(self.model, "predict_proba"):
            # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (–≤–∫–ª—é—á–∞—è –∞–Ω—Å–∞–º–±–ª—å)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ QuadEnsemble (—Ç—Ä–µ–±—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è LSTM)
            if hasattr(self.model, 'lstm_trainer') and hasattr(self.model, 'sequence_length'):
                # QuadEnsemble: –ø–µ—Ä–µ–¥–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º df_with_features, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ñ–∏—á–∏
                proba = self.model.predict_proba(X_last, df_history=df_with_features)[0]
            else:
                # –û–±—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω—Å–∞–º–±–ª–∏ (TripleEnsemble, etc.)
                proba = self.model.predict_proba(X_last)[0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º proba –Ω–∞ NaN
            if np.any(np.isnan(proba)) or not np.all(np.isfinite(proba)):
                # –ï—Å–ª–∏ proba —Å–æ–¥–µ—Ä–∂–∏—Ç NaN, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                proba = np.array([0.33, 0.34, 0.33])  # SHORT, HOLD, LONG
                logger.warning(f"[ml_strategy] Warning: proba contains NaN, using uniform distribution")
            
            # –î–ª—è –∞–Ω—Å–∞–º–±–ª—è proba —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
            if self.is_ensemble:
                # –ê–Ω—Å–∞–º–±–ª—å —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if np.isnan(long_prob) or not np.isfinite(long_prob):
                    long_prob = 0.0
                if np.isnan(short_prob) or not np.isfinite(short_prob):
                    short_prob = 0.0
                if np.isnan(hold_prob) or not np.isfinite(hold_prob):
                    hold_prob = 0.0
                
                # –õ–û–ì–ò–ö–ê –î–õ–Ø –ê–ù–°–ê–ú–ë–õ–ï–ô
                ensemble_absolute_min = 0.003  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0.3%
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É LONG –∏ SHORT
                prob_diff = abs(long_prob - short_prob)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                if long_prob >= ensemble_absolute_min and long_prob > short_prob and prob_diff >= self.min_confidence_difference:
                    prediction = 1  # LONG
                    confidence = min(long_prob * (1 + prob_diff * 0.3), long_prob)
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = long_prob
                elif short_prob >= ensemble_absolute_min and short_prob > long_prob and prob_diff >= self.min_confidence_difference:
                    prediction = -1  # SHORT
                    confidence = min(short_prob * (1 + prob_diff * 0.3), short_prob)
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = short_prob
                else:
                    prediction = 0
                    confidence = hold_prob
                
                # Fallback
                if prediction == 0:
                    prediction_idx = np.argmax(proba)
                    prediction = prediction_idx - 1
                    confidence = proba[prediction_idx]
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = hold_prob if np.isfinite(hold_prob) else 0.0
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            elif len(proba) == 3:
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1
                confidence = proba[prediction_idx]
                
                if np.isnan(confidence) or not np.isfinite(confidence):
                    confidence = 0.0
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç HOLD, –Ω–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                if np.isnan(long_prob) or not np.isfinite(long_prob):
                    long_prob = 0.0
                if np.isnan(short_prob) or not np.isfinite(short_prob):
                    short_prob = 0.0
                if np.isnan(hold_prob) or not np.isfinite(hold_prob):
                    hold_prob = 0.0
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥
                if self.use_dynamic_threshold and len(self.confidence_history) > 10:
                    recent_confidence_median = np.median(self.confidence_history[-20:])
                    adaptive_threshold = max(self.min_strength_threshold, recent_confidence_median * 0.9)
                else:
                    adaptive_threshold = self.min_strength_threshold
                
                if prediction == 0:
                    if long_prob >= adaptive_threshold and long_prob > short_prob:
                        prediction = 1
                        confidence = long_prob
                    elif short_prob >= adaptive_threshold and short_prob > long_prob:
                        prediction = -1
                        confidence = short_prob
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            else:
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1 if len(proba) == 3 else prediction_idx
                confidence = proba[prediction_idx]
                
                if np.isnan(prediction) or not np.isfinite(prediction):
                    prediction = 0
                if np.isnan(confidence) or not np.isfinite(confidence):
                    confidence = 0.0
        else:
            # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ predict_proba
            prediction_raw = self.model.predict(X_last)[0]
            if np.isnan(prediction_raw) or not np.isfinite(prediction_raw):
                prediction = 0
            else:
                if hasattr(self.model, 'classes_'):
                    classes = self.model.classes_
                    if len(classes) == 3:
                        prediction = int(prediction_raw) - 1
                    else:
                        prediction = int(prediction_raw)
                else:
                    prediction = int(prediction_raw)
            confidence = 1.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
        if np.isnan(prediction) or not np.isfinite(prediction):
            prediction = 0
        if np.isnan(confidence) or not np.isfinite(confidence):
            confidence = 0.0
        
        return int(prediction), float(confidence)
    
    def generate_signal(
        self,
        row: pd.Series,
        df: pd.DataFrame,
        has_position: Optional[Bias],
        current_price: float,
        leverage: int = 10,
        target_profit_pct_margin: float = 25.0,
        max_loss_pct_margin: float = 10.0,
    ) -> Signal:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
        
        –í–ê–ñ–ù–û: SL —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —É—Ä–æ–≤–Ω–µ–π (–ø–æ–¥–¥–µ—Ä–∂–∫–∞/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ)
                TP —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ RR 2-3:1 –æ—Ç SL
        
        Args:
            row: –¢–µ–∫—É—â–∏–π –±–∞—Ä (pd.Series)
            df: DataFrame —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            has_position: –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è (None, Bias.LONG, Bias.SHORT)
            current_price: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            leverage: –ü–ª–µ—á–æ (default: 10)
            target_profit_pct_margin: –¶–µ–ª–µ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ –≤ % (25%)
            max_loss_pct_margin: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫ –æ—Ç –º–∞—Ä–∂–∏ –≤ % (10%)
        
        Returns:
            Signal –æ–±—ä–µ–∫—Ç —Å —É—Ä–æ–≤–Ω–µ–≤—ã–º SL –∏ RR TP
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª
            symbol = getattr(self, '_symbol', None)
            if symbol is None:
                model_filename = Path(self.model_path).name
                if "_" in model_filename:
                    parts = model_filename.replace(".pkl", "").split("_")
                    if len(parts) >= 3 and parts[0] in ("triple", "quad") and parts[1] == "ensemble":
                        symbol = parts[2].upper()
                        self._symbol = symbol
                    elif len(parts) >= 2:
                        symbol = parts[1].upper()
                        self._symbol = symbol
                    else:
                        symbol = "UNKNOWN"
                else:
                    symbol = "UNKNOWN"
            
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            # –í–ê–ñ–ù–û: –ù–ï –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π, —á—Ç–æ–±—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ–±–Ω–æ–≤–ª—è–ª–∏—Å—å –¥–ª—è –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π
            prediction, confidence = self.predict(df, skip_feature_creation=False)
            
            # === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô CONFIDENCE THRESHOLD ===
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            effective_threshold = self.confidence_threshold
            
            if self.use_dynamic_threshold and prediction != 0:
                # –ü–æ–ª—É—á–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                atr_pct = row.get("atr_pct", np.nan)
                adx = row.get("adx", np.nan)
                
                # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (ATR)
                if np.isfinite(atr_pct):
                    # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å = –≤—ã—à–µ –ø–æ—Ä–æ–≥ (–±–æ–ª—å—à–µ —à—É–º–∞)
                    # –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å = –Ω–∏–∂–µ –ø–æ—Ä–æ–≥ (–º–µ–Ω—å—à–µ —à—É–º–∞)
                    if atr_pct > 1.5:  # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                        effective_threshold = self.confidence_threshold * 1.2
                    elif atr_pct < 0.5:  # –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                        effective_threshold = self.confidence_threshold * 0.9
                
                # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞ (ADX)
                if np.isfinite(adx):
                    # –°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥ (ADX < 20) = –≤—ã—à–µ –ø–æ—Ä–æ–≥ (–º–µ–Ω—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
                    # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ (ADX > 25) = –Ω–∏–∂–µ –ø–æ—Ä–æ–≥ (–±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
                    if adx < 20:  # –°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥
                        effective_threshold = max(effective_threshold, self.confidence_threshold * 1.15)
                    elif adx > 25:  # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
                        effective_threshold = min(effective_threshold, self.confidence_threshold * 0.95)
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω (0.3 - 0.8)
                effective_threshold = max(0.3, min(0.8, effective_threshold))
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥
            if prediction != 0 and confidence < effective_threshold:
                # –°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω –∏–∑-–∑–∞ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (—Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä–æ–≥–∞)
                return Signal(
                    timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                    action=Action.HOLD,
                    reason=f"ml_–Ω–∏–∑–∫–∞—è_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å_{int(confidence*100)}%_–ø–æ—Ä–æ–≥_{int(effective_threshold*100)}%",
                    price=current_price,
                    indicators_info={
                        "strategy": "ML",
                        "prediction": "HOLD",
                        "confidence": round(confidence, 4),
                        "threshold": round(effective_threshold, 4),
                        "rejected_reason": "dynamic_threshold"
                    }
                )
            
            # === –†–ê–°–ß–ï–¢ SL –û–¢ –£–†–û–í–ù–ï–ô + TP –ü–û RR 2-3:1 ===
            sl_price = None
            tp_price = None
            sl_source = None
            sl_level = None

            def _is_finite_number(value: Any) -> bool:
                try:
                    return value is not None and np.isfinite(float(value))
                except Exception:
                    return False

            def _collect_level_candidates(side: str) -> list[tuple[str, float]]:
                candidates: list[tuple[str, float]] = []
                if df is None or len(df) == 0:
                    return candidates
                lookback = min(60, len(df))
                df_tail = df.iloc[-lookback:]

                recent_low = df_tail["low"].min() if "low" in df_tail.columns else None
                recent_high = df_tail["high"].max() if "high" in df_tail.columns else None

                def add_candidate(name: str, value: Any, compare: str):
                    if not _is_finite_number(value):
                        return
                    value_f = float(value)
                    if compare == "below" and value_f < current_price:
                        candidates.append((name, value_f))
                    elif compare == "above" and value_f > current_price:
                        candidates.append((name, value_f))

                if side == "LONG":
                    add_candidate("recent_low", recent_low, "below")
                    add_candidate("bb_lower", row.get("bb_lower"), "below")
                    add_candidate("sma_20", row.get("sma_20"), "below")
                    add_candidate("ema_26", row.get("ema_26"), "below")
                    add_candidate("ema_12", row.get("ema_12"), "below")
                else:
                    add_candidate("recent_high", recent_high, "above")
                    add_candidate("bb_upper", row.get("bb_upper"), "above")
                    add_candidate("sma_20", row.get("sma_20"), "above")
                    add_candidate("ema_26", row.get("ema_26"), "above")
                    add_candidate("ema_12", row.get("ema_12"), "above")

                return candidates

            def _calculate_sl_from_levels(side: str) -> tuple[Optional[float], Optional[str], Optional[float]]:
                candidates = _collect_level_candidates(side)
                if not candidates:
                    return None, None, None
                if side == "LONG":
                    # –ë–ª–∏–∂–∞–π—à–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (—Å–∞–º–∞—è –≤—ã—Å–æ–∫–∞—è –Ω–∏–∂–µ —Ü–µ–Ω—ã)
                    selected = max(candidates, key=lambda x: x[1])
                else:
                    # –ë–ª–∏–∂–∞–π—à–µ–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ (—Å–∞–º–æ–µ –Ω–∏–∑–∫–æ–µ –≤—ã—à–µ —Ü–µ–Ω—ã)
                    selected = min(candidates, key=lambda x: x[1])

                level_name, level_price = selected

                # –ë—É—Ñ–µ—Ä –∑–∞ —É—Ä–æ–≤–Ω–µ–º (ATR –∏–ª–∏ –º–∏–Ω–∏–º—É–º 0.1%)
                atr_value = row.get("atr")
                if _is_finite_number(atr_value) and float(atr_value) > 0:
                    buffer_value = max(current_price * 0.001, float(atr_value) * 0.2)
                else:
                    buffer_value = current_price * 0.001

                if side == "LONG":
                    sl = level_price - buffer_value
                else:
                    sl = level_price + buffer_value

                if side == "LONG" and sl >= current_price:
                    return None, None, None
                if side == "SHORT" and sl <= current_price:
                    return None, None, None

                return sl, level_name, level_price

            # –ö–†–ò–¢–ò–ß–ù–û: –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º SL=1% (—Å—Ç—Ä–æ–≥–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ)
            # –£—Ä–æ–≤–Ω–∏ S/R –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –Ω–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ SL
            if prediction == 1:
                # LONG: SL = —Ü–µ–Ω–∞ * 0.99 (—Å—Ç—Ä–æ–≥–æ 1% –Ω–∏–∂–µ)
                sl_price = current_price * 0.99
                sl_source = "fixed_1pct"
                sl_level = None
            elif prediction == -1:
                # SHORT: SL = —Ü–µ–Ω–∞ * 1.01 (—Å—Ç—Ä–æ–≥–æ 1% –≤—ã—à–µ)
                sl_price = current_price * 1.01
                sl_source = "fixed_1pct"
                sl_level = None
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—Ä–æ–≤–µ—Ä—è–µ–º —É—Ä–æ–≤–Ω–∏ S/R –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è SL)
            if prediction != 0:
                sl_from_levels, _, _ = _calculate_sl_from_levels("LONG" if prediction == 1 else "SHORT")
                if sl_from_levels is not None:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±–ª–∏–∑–æ–∫ –ª–∏ SL –æ—Ç —É—Ä–æ–≤–Ω–µ–π –∫ 1% (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö ¬±0.2%)
                    if prediction == 1:
                        sl_distance_from_levels = (current_price - sl_from_levels) / current_price
                        if 0.008 <= sl_distance_from_levels <= 0.012:  # 0.8% - 1.2%
                            # SL –æ—Ç —É—Ä–æ–≤–Ω–µ–π –±–ª–∏–∑–æ–∫ –∫ 1%, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ (–Ω–æ —ç—Ç–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                            # –î–ª—è —Å—Ç—Ä–æ–≥–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π 1%
                            pass
                    else:  # SHORT
                        sl_distance_from_levels = (sl_from_levels - current_price) / current_price
                        if 0.008 <= sl_distance_from_levels <= 0.012:  # 0.8% - 1.2%
                            # SL –æ—Ç —É—Ä–æ–≤–Ω–µ–π –±–ª–∏–∑–æ–∫ –∫ 1%, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ (–Ω–æ —ç—Ç–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                            # –î–ª—è —Å—Ç—Ä–æ–≥–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π 1%
                            pass

            # RR 2-3:1 (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–æ –≤—Å–µ–≥–¥–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ)
            rr = 2.0
            if _is_finite_number(confidence):
                rr = 2.0 + min(1.0, max(0.0, (confidence - 0.5) / 0.4))
            rr = float(min(3.0, max(2.0, rr)))

            if prediction == 1 and sl_price is not None:
                risk = abs(current_price - sl_price)
                tp_price = current_price + (risk * rr)
            elif prediction == -1 and sl_price is not None:
                risk = abs(sl_price - current_price)
                tp_price = current_price - (risk * rr)
            
            # –£–õ–£–ß–®–ï–ù–ò–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è TP/SL (–∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å TP/SL –¥–ª—è LONG
            if prediction == 1 and tp_price is not None and sl_price is not None:
                if not (sl_price < current_price and tp_price > current_price):
                    sl_price = current_price * 0.99
                    tp_price = current_price * 1.025
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å TP/SL –¥–ª—è SHORT
            if prediction == -1 and tp_price is not None and sl_price is not None:
                if not (sl_price > current_price and tp_price < current_price):
                    sl_price = current_price * 1.01
                    tp_price = current_price * 0.975
            
            # –£–õ–£–ß–®–ï–ù–ò–ï: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å (–∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ TP/SL –Ω–µ–≤–∞–ª–∏–¥–Ω—ã, –º—ã –∏—Ö –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º –ø–æ–∑–∂–µ, –Ω–æ –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ None
            # –¥–ª—è LONG/SHORT —Å–∏–≥–Ω–∞–ª–æ–≤, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –í–°–ï–ì–î–ê –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å TP/SL
            if tp_price is not None and sl_price is not None:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–µ–Ω—ã –Ω–µ NaN –∏ –Ω–µ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã
                if not (np.isfinite(tp_price) and np.isfinite(sl_price)):
                    # –î–ª—è LONG/SHORT –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º, –∞ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º None
                    if prediction == 1:  # LONG
                        sl_price = current_price * 0.99
                        tp_price = current_price * 1.025
                    elif prediction == -1:  # SHORT
                        sl_price = current_price * 1.01
                        tp_price = current_price * 0.975
                    else:
                        tp_price = None
                        sl_price = None
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                elif tp_price <= 0 or sl_price <= 0:
                    # –î–ª—è LONG/SHORT –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º, –∞ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º None
                    if prediction == 1:  # LONG
                        sl_price = current_price * 0.99
                        tp_price = current_price * 1.025
                    elif prediction == -1:  # SHORT
                        sl_price = current_price * 1.01
                        tp_price = current_price * 0.975
                    else:
                        tp_price = None
                        sl_price = None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if confidence >= 0.9:
                strength = "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.8:
                strength = "—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.7:
                strength = "—Å—Ä–µ–¥–Ω–µ–µ"
            elif confidence >= 0.6:
                strength = "—É–º–µ—Ä–µ–Ω–Ω–æ–µ"
            else:
                strength = "—Å–ª–∞–±–æ–µ"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∏—á–∏–Ω—É
            confidence_pct = int(confidence * 100) if np.isfinite(confidence) else 0
            tp_pct_display = (abs(tp_price - current_price) / current_price) * 100 if tp_price else 0.0
            sl_pct_display = (abs(current_price - sl_price) / current_price) * 100 if sl_price else 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
            from datetime import datetime, timezone
            current_date = datetime.now(timezone.utc).date()
            date_str = current_date.isoformat()
            signals_today = self.daily_signals_count.get(date_str, 0)
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞
            if self.is_ensemble:
                min_strength = 0.003  # 0.3% –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π
            else:
                min_strength = 0.6  # 60% –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            
            if prediction != 0 and confidence < min_strength:
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è ML (–¥–∞–∂–µ –¥–ª—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤)
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "HOLD",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "leverage": leverage,
                    "has_position": has_position.value if has_position else None,
                    "rejected_reason": f"confidence_too_low_min_{int(min_strength*100)}%"
                }
                return Signal(
                    timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                    action=Action.HOLD, 
                    reason=f"ml_—Å–∏–ª–∞_—Å–ª–∏—à–∫–æ–º_—Å–ª–∞–±–∞—è_{strength}_{confidence_pct}%_–º–∏–Ω_{int(min_strength*100)}%", 
                    price=current_price,
                    indicators_info=indicators_info
                )
            
            # –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è, —Ç—Ä–µ–±—É–µ–º –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if self.stability_filter and prediction != 0:
                if has_position == Bias.SHORT and prediction == 1:
                    # –ï—Å—Ç—å SHORT, —Ö–æ—Ç–∏–º –æ—Ç–∫—Ä—ã—Ç—å LONG - –Ω—É–∂–Ω–∞ –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    stability_threshold = max(confidence * 1.3, min_strength * 1.5)
                    if confidence < stability_threshold:
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%_–ø—Ä–æ—Ç–∏–≤_SHORT", 
                            current_price
                        )
                elif has_position == Bias.LONG and prediction == -1:
                    # –ï—Å—Ç—å LONG, —Ö–æ—Ç–∏–º –æ—Ç–∫—Ä—ã—Ç—å SHORT - –Ω—É–∂–Ω–∞ –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    stability_threshold = max(confidence * 1.3, min_strength * 1.5)
                    if confidence < stability_threshold:
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%_–ø—Ä–æ—Ç–∏–≤_LONG", 
                            current_price
                        )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤
            is_volatile_symbol = symbol in ("ETHUSDT", "SOLUSDT")
            
            # –§–∏–ª—å—Ç—Ä –ø–æ RSI –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω
            rsi = row.get("rsi", np.nan)
            if prediction != 0 and np.isfinite(rsi):
                if (prediction == 1 and rsi > 85) or (prediction == -1 and rsi < 15):
                    # –í —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω–∞—Ö —Ç—Ä–µ–±—É–µ–º –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    extreme_threshold = confidence * 1.2
                    if confidence < extreme_threshold:
                        rsi_int = int(rsi) if np.isfinite(rsi) else 0
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π_RSI_{rsi_int}_{strength}_{confidence_pct}%", 
                            current_price
                        )
            
            # –§–∏–ª—å—Ç—Ä –ø–æ –æ–±—ä–µ–º—É (—Ç–æ–ª—å–∫–æ –¥–ª—è —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ > 0.7)
            if confidence > 0.7:
                volume = row.get("volume", np.nan)
                vol_sma = row.get("vol_sma", np.nan)
                if not np.isfinite(vol_sma):
                    vol_sma = row.get("volume_sma_20", np.nan)
                
                if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0:
                    volume_ratio = volume / vol_sma
                    if volume_ratio < 0.5:  # –û–±—ä–µ–º –º–µ–Ω—å—à–µ 50% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_–Ω–∏–∑–∫–∏–π_–æ–±—ä–µ–º_{volume_ratio:.1f}x_{strength}_{confidence_pct}%", 
                            current_price
                        )
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ TP/SL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π LONG/SHORT —Å–∏–≥–Ω–∞–ª–æ–≤
            if prediction != 0 and (tp_price is None or sl_price is None):
                # –ï—Å–ª–∏ TP/SL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∏—Ö –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                if prediction == 1:  # LONG
                    sl_price = current_price * 0.99  # 1% –Ω–∏–∂–µ
                    tp_price = current_price + (abs(current_price - sl_price) * rr)
                    sl_source = sl_source or "fallback_1pct"
                elif prediction == -1:  # SHORT
                    sl_price = current_price * 1.01  # 1% –≤—ã—à–µ
                    tp_price = current_price - (abs(sl_price - current_price) * rr)
                    sl_source = sl_source or "fallback_1pct"

            if prediction != 0:
                tp_pct_display = (abs(tp_price - current_price) / current_price) * 100 if tp_price else 0.0
                sl_pct_display = (abs(current_price - sl_price) / current_price) * 100 if sl_price else 0.0
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            if prediction == 1:  # LONG
                # –ö–†–ò–¢–ò–ß–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP/SL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏ –≤–∞–ª–∏–¥–Ω—ã
                if tp_price is None or sl_price is None or not np.isfinite(tp_price) or not np.isfinite(sl_price) or tp_price <= 0 or sl_price <= 0:
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TP/SL
                    sl_price = current_price * 0.99  # 1% –Ω–∏–∂–µ (—Å—Ç—Ä–æ–≥–æ 1.0%)
                    tp_price = current_price * 1.025  # 2.5% –≤—ã—à–µ (–±–∞–∑–æ–≤—ã–π TP)
                    sl_pct_display = 1.0
                    tp_pct_display = 2.5
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ SL < —Ü–µ–Ω–∞ < TP –¥–ª—è LONG
                if sl_price >= current_price or tp_price <= current_price:
                    sl_price = current_price * 0.99
                    tp_price = current_price * 1.025
                
                reason = f"ml_LONG_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct_display:.1f}%_SL_{sl_pct_display:.1f}%"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤
                self.signal_history.append((row.name, Action.LONG, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –¥–µ–Ω—å
                self.daily_signals_count[date_str] = signals_today + 1
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
                from datetime import timedelta
                cutoff_date = (current_date - timedelta(days=7)).isoformat()
                self.daily_signals_count = {k: v for k, v in self.daily_signals_count.items() if k >= cutoff_date}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è ML (—Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "LONG",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct_display, 2),
                    "sl_pct": round(sl_pct_display, 2),
                    "target_profit_margin_pct": target_profit_pct_margin,
                    "max_loss_margin_pct": max_loss_pct_margin,
                    "leverage": leverage,
                    "has_position": has_position.value if has_position else None,
                    "stop_loss": sl_price,   # –¶–µ–Ω–∞ SL
                    "take_profit": tp_price,  # –¶–µ–Ω–∞ TP
                    "sl_source": sl_source,
                    "sl_level": sl_level,
                    "risk_reward": round(rr, 2),
                }
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º ATR –≤ indicators_info –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω (–∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
                try:
                    if 'atr' in df.columns and len(df) > 0:
                        current_atr = df['atr'].iloc[-1]
                        if pd.notna(current_atr) and current_atr > 0:
                            indicators_info['atr'] = float(current_atr)
                            indicators_info['atr_pct'] = round((current_atr / current_price) * 100, 3)
                except Exception:
                    pass
                
                # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP/SL –≤–∞–ª–∏–¥–Ω—ã –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
                if sl_price is None or tp_price is None or not np.isfinite(sl_price) or not np.isfinite(tp_price) or sl_price <= 0 or tp_price <= 0:
                    logger.error(f"CRITICAL: Invalid TP/SL for LONG signal! sl_price={sl_price}, tp_price={tp_price}, price={current_price}")
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    sl_price = current_price * 0.99
                    tp_price = current_price * 1.025
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–ª—è LONG
                if sl_price >= current_price or tp_price <= current_price:
                    logger.warning(f"Fixing invalid TP/SL for LONG: sl={sl_price}, tp={tp_price}, price={current_price}")
                    sl_price = current_price * 0.99
                    tp_price = current_price * 1.025
                
                # –û–±–Ω–æ–≤–ª—è–µ–º indicators_info —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ TP/SL
                indicators_info['stop_loss'] = sl_price
                indicators_info['take_profit'] = tp_price
                
                return Signal(
                    timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                    action=Action.LONG,
                    reason=reason,
                    price=current_price,
                    stop_loss=sl_price,  # –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≤–∞–ª–∏–¥–µ–Ω
                    take_profit=tp_price,  # –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≤–∞–ª–∏–¥–µ–Ω
                    indicators_info=indicators_info
                )
            
            elif prediction == -1:  # SHORT
                # –ö–†–ò–¢–ò–ß–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP/SL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏ –≤–∞–ª–∏–¥–Ω—ã
                if tp_price is None or sl_price is None or not np.isfinite(tp_price) or not np.isfinite(sl_price) or tp_price <= 0 or sl_price <= 0:
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TP/SL
                    sl_price = current_price * 1.01  # 1% –≤—ã—à–µ (—Å—Ç—Ä–æ–≥–æ 1.0%)
                    tp_price = current_price * 0.975  # 2.5% –Ω–∏–∂–µ (–±–∞–∑–æ–≤—ã–π TP)
                    sl_pct_display = 1.0
                    tp_pct_display = 2.5
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP < —Ü–µ–Ω–∞ < SL –¥–ª—è SHORT
                if tp_price >= current_price or sl_price <= current_price:
                    sl_price = current_price * 1.01
                    tp_price = current_price * 0.975
                
                reason = f"ml_SHORT_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct_display:.1f}%_SL_{sl_pct_display:.1f}%"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤
                self.signal_history.append((row.name, Action.SHORT, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –¥–µ–Ω—å
                self.daily_signals_count[date_str] = signals_today + 1
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
                from datetime import timedelta
                cutoff_date = (current_date - timedelta(days=7)).isoformat()
                self.daily_signals_count = {k: v for k, v in self.daily_signals_count.items() if k >= cutoff_date}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è ML (—Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "SHORT",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct_display, 2),
                    "sl_pct": round(sl_pct_display, 2),
                    "target_profit_margin_pct": target_profit_pct_margin,
                    "max_loss_margin_pct": max_loss_pct_margin,
                    "leverage": leverage,
                    "has_position": has_position.value if has_position else None,
                    "stop_loss": sl_price,   # –¶–µ–Ω–∞ SL
                    "take_profit": tp_price,  # –¶–µ–Ω–∞ TP
                    "sl_source": sl_source,
                    "sl_level": sl_level,
                    "risk_reward": round(rr, 2),
                }
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º ATR –≤ indicators_info –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω (–∏–∑ —É—Å–ø–µ—à–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞)
                try:
                    if 'atr' in df.columns and len(df) > 0:
                        current_atr = df['atr'].iloc[-1]
                        if pd.notna(current_atr) and current_atr > 0:
                            indicators_info['atr'] = float(current_atr)
                            indicators_info['atr_pct'] = round((current_atr / current_price) * 100, 3)
                except Exception:
                    pass
                
                # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP/SL –≤–∞–ª–∏–¥–Ω—ã –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
                if sl_price is None or tp_price is None or not np.isfinite(sl_price) or not np.isfinite(tp_price) or sl_price <= 0 or tp_price <= 0:
                    logger.error(f"CRITICAL: Invalid TP/SL for SHORT signal! sl_price={sl_price}, tp_price={tp_price}, price={current_price}")
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    sl_price = current_price * 1.01
                    tp_price = current_price * 0.975
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–ª—è SHORT
                if tp_price >= current_price or sl_price <= current_price:
                    logger.warning(f"Fixing invalid TP/SL for SHORT: sl={sl_price}, tp={tp_price}, price={current_price}")
                    sl_price = current_price * 1.01
                    tp_price = current_price * 0.975
                
                # –û–±–Ω–æ–≤–ª—è–µ–º indicators_info —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ TP/SL
                indicators_info['stop_loss'] = sl_price
                indicators_info['take_profit'] = tp_price
                
                return Signal(
                    timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                    action=Action.SHORT,
                    reason=reason,
                    price=current_price,
                    stop_loss=sl_price,  # –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≤–∞–ª–∏–¥–µ–Ω
                    take_profit=tp_price,  # –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≤–∞–ª–∏–¥–µ–Ω
                    indicators_info=indicators_info
                )
            
            else:  # prediction == 0 (HOLD)
                reason = f"ml_–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ_—Å–∏–ª–∞_{strength}_{confidence_pct}%_–æ–∂–∏–¥–∞–Ω–∏–µ"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ (HOLD —Ç–æ–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º)
                self.signal_history.append((row.name, Action.HOLD, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è ML (–¥–∞–∂–µ –¥–ª—è HOLD)
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "HOLD",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "leverage": leverage,
                    "has_position": has_position.value if has_position else None,
                }
                
                return Signal(
                    timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                    action=Action.HOLD,
                    reason=reason,
                    price=current_price,
                    indicators_info=indicators_info
                )
        
        except Exception as e:
            logger.error(f"[ml_strategy] Error generating signal: {e}")
            import traceback
            traceback.print_exc()
            return Signal(
                timestamp=row.name if hasattr(row, 'name') else pd.Timestamp.now(),
                action=Action.HOLD,
                reason=f"ml_–æ—à–∏–±–∫–∞_{str(e)[:20]}",
                price=current_price
            )


def build_ml_signals(
    df: pd.DataFrame,
    model_path: str,
    confidence_threshold: float = 0.5,
    min_signal_strength: str = "—Å–ª–∞–±–æ–µ",
    stability_filter: bool = True,
    leverage: int = 10,
    target_profit_pct_margin: float = 25.0,
    max_loss_pct_margin: float = 10.0,
    min_signals_per_day: int = 1,
    max_signals_per_day: int = 10,
) -> list[Signal]:
    """
    –°—Ç—Ä–æ–∏—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame.
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å OHLCV –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
        model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞
        stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        leverage: –ü–ª–µ—á–æ (default: 10)
        target_profit_pct_margin: –¶–µ–ª–µ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ –≤ % (25%)
        max_loss_pct_margin: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫ –æ—Ç –º–∞—Ä–∂–∏ –≤ % (10%)
    
    Returns:
        –°–ø–∏—Å–æ–∫ Signal –æ–±—ä–µ–∫—Ç–æ–≤
    """
    strategy = MLStrategy(
        model_path, 
        confidence_threshold, 
        min_signal_strength, 
        stability_filter,
        min_signals_per_day=min_signals_per_day,
        max_signals_per_day=max_signals_per_day
    )
    signals: list[Signal] = []
    position_bias: Optional[Bias] = None
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ DataFrame –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    df_work = df.copy()
    
    # –ï—Å–ª–∏ timestamp –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å
    if "timestamp" in df_work.columns:
        df_work = df_work.set_index("timestamp")
    elif not isinstance(df_work.index, pd.DatetimeIndex):
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å –≤ DatetimeIndex
        try:
            df_work.index = pd.to_datetime(df_work.index)
        except:
            pass
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ OHLCV
    required_cols = ["open", "high", "low", "close", "volume"]
    if not all(col in df_work.columns for col in required_cols):
        logger.warning(f"[ml_strategy] Warning: Missing required columns. Available: {df_work.columns.tolist()}")
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), 
                       Action.HOLD, "ml_missing_data", 0.0) 
                for i in range(len(df_work))]
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏—á–∏ –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ–≥–æ DataFrame
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ MTF-—Ä–µ–∂–∏–º
        import os
        ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "0")
        ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")

        # –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ 15m
        df_with_features = strategy.feature_engineer.create_technical_indicators(df_work)

        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω MTF-—Ä–µ–∂–∏–º, –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∏—á–∏ 1h/4h
        if ml_mtf_enabled:
            try:
                # –°—Ç—Ä–æ–∏–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ OHLCV –¥–ª—è 1h –∏ 4h –∏–∑ 15m –¥–∞–Ω–Ω—ã—Ö
                ohlcv_agg = {
                    "open": "first",
                    "high": "max",
                    "low": "min",
                    "close": "last",
                    "volume": "sum",
                }
                df_1h = df_work.resample("60min").agg(ohlcv_agg).dropna()
                df_4h = df_work.resample("240min").agg(ohlcv_agg).dropna()

                higher_timeframes = {}
                if df_1h is not None and not df_1h.empty:
                    higher_timeframes["60"] = df_1h
                if df_4h is not None and not df_4h.empty:
                    higher_timeframes["240"] = df_4h

                if higher_timeframes:
                    df_with_features = strategy.feature_engineer.add_mtf_features(
                        df_with_features,
                        higher_timeframes,
                    )
                    logger.debug(f"[ml_strategy] MTF features enabled for ML signals (1h/4h). Columns: {len(df_with_features.columns)}")
                else:
                    logger.warning("[ml_strategy] MTF enabled but failed to build 1h/4h data ‚Äì using 15m-only features")
            except Exception as mtf_err:
                logger.warning(f"[ml_strategy] Warning: failed to add MTF features in build_ml_signals: {mtf_err}")
    except Exception as e:
        logger.error(f"[ml_strategy] Error preparing features: {e}")
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), 
                       Action.HOLD, f"ml_error_{str(e)[:20]}", 0.0) 
                for i in range(len(df_work))]
    
    for idx, row in df_with_features.iterrows():
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞
            df_until_now = df_with_features.loc[:idx]
            
            # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 200 –±–∞—Ä–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if len(df_until_now) < 200:
                signals.append(Signal(idx, Action.HOLD, "ml_insufficient_data", row["close"]))
                continue
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
            signal = strategy.generate_signal(
                row=row,
                df=df_until_now,
                has_position=position_bias,
                current_price=row["close"],
                leverage=leverage,
                target_profit_pct_margin=target_profit_pct_margin,
                max_loss_pct_margin=max_loss_pct_margin,
            )
            signals.append(signal)
        except Exception as e:
            logger.error(f"[ml_strategy] Error processing row {idx}: {e}")
            signals.append(Signal(idx, Action.HOLD, f"ml_error_{str(e)[:20]}", row.get("close", 0.0)))
    
    return signals