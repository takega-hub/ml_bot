"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤.

–£–ª—É—á—à–µ–Ω–∏—è:
1. –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç (movement > 1%)
2. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (class_weight)
3. –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –¥–Ω–µ–π)
4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
"""
import warnings
import os
import sys

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows (–ë–ï–ó–û–ü–ê–°–ù–ê–Ø –í–ï–†–°–ò–Ø)
if sys.platform == 'win32':
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–º–µ–Ω—É –æ—à–∏–±–æ–∫ –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ stdout/stderr
        import codecs
        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω
        if sys.stdout.isatty():
            sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'replace')
        if sys.stderr.isatty():
            sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'replace')
    except:
        pass  # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
warnings.filterwarnings('ignore')

from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from bot.config import load_settings
from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer, WeightedEnsemble, TripleEnsemble

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ (–∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è Windows)
def safe_print(*args, **kwargs):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π print, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏."""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–≤–µ—Å—Ç–∏ –∫–∞–∫ –µ—Å—Ç—å
        print(*args, **kwargs)
        sys.stdout.flush()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
    except (UnicodeEncodeError, IOError) as e:
        try:
            # –ó–∞–º–µ–Ω—è–µ–º —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏
            text = ' '.join(str(arg) for arg in args)
            # –û—Å–Ω–æ–≤–Ω—ã–µ —ç–º–æ–¥–∑–∏
            replacements = {
                'üöÄ': '[START]',
                'üìä': '[INFO]', 
                '‚úÖ': '[OK]',
                '‚ùå': '[ERROR]',
                '‚è≥': '[WAIT]',
                'üî•': '[HOT]',
                'üì•': '[DOWNLOAD]',
                'üîß': '[ENGINEERING]',
                'üéØ': '[TARGET]',
                'üì¶': '[DATA]',
                'ü§ñ': '[MODEL]',
                'üå≤': '[RF]',
                '‚ö°': '[XGB]',
                'üéâ': '[SUCCESS]',
                'üí°': '[TIP]',
                'üîÑ': '[RETRAIN]',
                'üìã': '[LIST]',
                'üîç': '[SEARCH]',
                'üìà': '[CHART]',
                'üß™': '[TEST]',
                '‚öôÔ∏è': '[SETTINGS]'
            }
            for emoji, replacement in replacements.items():
                text = text.replace(emoji, replacement)
            
            # –í—ã–≤–æ–¥–∏–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            print(text, **kwargs)
            sys.stdout.flush()
        except:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –≤—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
            try:
                text = ' '.join(str(arg) for arg in args)
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ã
                text = ''.join(c for c in text if ord(c) < 128)
                print(text, **kwargs)
            except:
                print("[ERROR: Could not print message]", **kwargs)


def load_optimized_weights(weights_file: str = None) -> dict:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞.
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞: {symbol: {model_name: weight}}
    """
    try:
        from apply_optimized_weights import load_optimized_weights as load_weights
        return load_weights(Path(weights_file) if weights_file else None)
    except ImportError:
        # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é
        import json
        from pathlib import Path
        
        if weights_file is None:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª
            weights_files = sorted(
                Path(".").glob("ensemble_weights_all_*.json"),
                key=lambda p: p.stat().st_mtime if p.exists() else 0,
                reverse=True
            )
            if not weights_files:
                return {}
            weights_file = weights_files[0]
        
        weights_file = Path(weights_file)
        if not weights_file.exists():
            return {}
        
        with open(weights_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        weights_dict = {}
        if isinstance(data, list):
            for item in data:
                symbol = item.get("symbol", "").upper()
                weights = item.get("weights", {})
                if symbol and weights:
                    weights_dict[symbol] = weights
        
        return weights_dict


def main():
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    import argparse
    parser = argparse.ArgumentParser(
        description="–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ MTF —Ñ–∏—á–∞–º–∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –û–±—É—á–µ–Ω–∏–µ –ë–ï–ó MTF (—Ç–æ–ª—å–∫–æ 15m —Ñ–∏—á–∏)
  python retrain_ml_optimized.py --no-mtf
  
  # –û–±—É—á–µ–Ω–∏–µ –° MTF (15m + 1h + 4h —Ñ–∏—á–∏)
  python retrain_ml_optimized.py --mtf
  
  # –û–±—É—á–µ–Ω–∏–µ –ë–ï–ó MTF –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
  python retrain_ml_optimized.py --symbol SOLUSDT --no-mtf
        """
    )
    parser.add_argument("--symbol", type=str, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    parser.add_argument(
        "--mtf", 
        action="store_true", 
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MTF —Ñ–∏—á–∏ (1h, 4h) - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–æ"
    )
    parser.add_argument(
        "--no-mtf", 
        action="store_true", 
        help="–ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MTF —Ñ–∏—á–∏ (—Ç–æ–ª—å–∫–æ 15m)"
    )
    parser.add_argument(
        "--use-optimized-weights",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª–µ–π –∏–∑ —Ñ–∞–π–ª–∞ ensemble_weights_all_*.json"
    )
    parser.add_argument(
        "--weights-file",
        type=str,
        help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—â–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π)"
    )
    parser.add_argument(
        "--interval",
        type=str,
        default="15m",
        choices=["15m", "60m", "1h"],
        help="–ë–∞–∑–æ–≤—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (15m –∏–ª–∏ 60m/1h). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 15m"
    )
    args = parser.parse_known_args()[0]
    
    safe_print("=" * 80)
    safe_print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò")
    safe_print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = load_settings()
    
    # –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    symbols = [args.symbol] if args.symbol else ["BNBUSDT", "ADAUSDT"]
    #["SOLUSDT", "BTCUSDT", "ETHUSDT", "XRPUSDT"]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
    interval_str = args.interval.lower().replace("h", "m")  # "1h" -> "60m"
    if interval_str == "60m":
        base_interval = "60"  # 1 —á–∞—Å
        interval_display = "1h"
    else:
        base_interval = "15"  # 15 –º–∏–Ω—É—Ç
        interval_display = "15m"
    
    safe_print(f"üìå –ë–∞–∑–æ–≤—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {interval_display}")
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ MTF-—Ä–µ–∂–∏–º –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: --no-mtf > --mtf > –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è > –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–≤–∫–ª—é—á–µ–Ω–æ)
    if args.no_mtf:
        ml_mtf_enabled = False
        safe_print("üìå –†–µ–∂–∏–º: –ë–ï–ó MTF —Ñ–∏—á–µ–π (—Ç–æ–ª—å–∫–æ 15m)")
    elif args.mtf:
        ml_mtf_enabled = True
        safe_print("üìå –†–µ–∂–∏–º: –° MTF —Ñ–∏—á–∞–º–∏ (15m + 1h + 4h)")
    else:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ —Ñ–ª–∞–≥–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã
        ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "1")
        ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")
        if ml_mtf_enabled:
            safe_print("üìå –†–µ–∂–∏–º: –° MTF —Ñ–∏—á–∞–º–∏ (15m + 1h + 4h) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é]")
        else:
            safe_print("üìå –†–µ–∂–∏–º: –ë–ï–ó MTF —Ñ–∏—á–µ–π (—Ç–æ–ª—å–∫–æ 15m) [–∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è]")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
    if ml_mtf_enabled:
        mode_suffix = f"mtf_{interval_display}"
    else:
        mode_suffix = interval_display
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    optimized_weights = {}
    if args.use_optimized_weights:
        try:
            optimized_weights = load_optimized_weights(args.weights_file)
            if optimized_weights:
                safe_print(f"\n[OK] –ó–∞–≥—Ä—É–∂–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è {len(optimized_weights)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                safe_print(f"\n[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞, –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤–µ—Å–∞ –∏–∑ CV")
        except Exception as e:
            safe_print(f"\n[WARNING] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤: {e}")
            safe_print(f"         –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤–µ—Å–∞ –∏–∑ CV")
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
        safe_print("\n" + "=" * 80)
        safe_print(f"üìä –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø {symbol}")
        safe_print("=" * 80)
        
        # === –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (30 –¥–Ω–µ–π) ===
        if ml_mtf_enabled:
            if base_interval == "15":
                safe_print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ({interval_display}, 1h, 4h) –¥–ª—è {symbol}...")
                mtf_intervals = [base_interval, "60", "240"]  # 15m, 1h, 4h
            else:  # base_interval == "60" (1h)
                safe_print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ({interval_display}, 4h, 1d) –¥–ª—è {symbol}...")
                mtf_intervals = [base_interval, "240", "D"]  # 1h, 4h, 1d
        else:
            safe_print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ({interval_display} only) –¥–ª—è {symbol}...")
        collector = DataCollector(settings.api)
        
        if ml_mtf_enabled:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            mtf_data = collector.collect_multiple_timeframes(
                symbol=symbol,
                intervals=mtf_intervals,
                start_date=None,
                end_date=None,
            )
            
            df_raw_base = mtf_data.get(base_interval)
            if base_interval == "15":
                df_raw_1h = mtf_data.get("60")
                df_raw_4h = mtf_data.get("240")
            else:  # 1h
                df_raw_4h = mtf_data.get("240")
                df_raw_1d = mtf_data.get("D")
            
            if df_raw_base is None or df_raw_base.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö ({interval_display}) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            
            candles_per_day = 96 if base_interval == "15" else 24  # 15m: 96 —Å–≤–µ—á–µ–π/–¥–µ–Ω—å, 1h: 24 —Å–≤–µ—á–∏/–¥–µ–Ω—å
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_base)} —Å–≤–µ—á–µ–π {interval_display} (~{len(df_raw_base)/candles_per_day:.1f} –¥–Ω–µ–π)")
        else:
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            df_raw_base = collector.collect_klines(
                symbol=symbol,
                interval=base_interval,
                start_date=None,
                end_date=None,
                limit=3000,
            )
            if df_raw_base.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö ({interval_display}) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            candles_per_day = 96 if base_interval == "15" else 24
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_base)} —Å–≤–µ—á–µ–π {interval_display} (~{len(df_raw_base)/candles_per_day:.1f} –¥–Ω–µ–π)")
        
        # === –®–∞–≥ 2: Feature Engineering ===
        safe_print(f"\n[2/5] üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}...")
        feature_engineer = FeatureEngineer()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –±–∞–∑–æ–≤–æ–º –¢–§
        df_features = feature_engineer.create_technical_indicators(df_raw_base)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º—É–ª—å—Ç–∏‚Äë—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å –∏ MTF –≤–∫–ª—é—á–µ–Ω
        if ml_mtf_enabled:
            higher_timeframes = {}
            if base_interval == "15":
                df_raw_1h = mtf_data.get("60")
                df_raw_4h = mtf_data.get("240")
                if df_raw_1h is not None and not df_raw_1h.empty:
                    higher_timeframes["60"] = df_raw_1h
                if df_raw_4h is not None and not df_raw_4h.empty:
                    higher_timeframes["240"] = df_raw_4h
            else:  # base_interval == "60" (1h)
                df_raw_4h = mtf_data.get("240")
                df_raw_1d = mtf_data.get("D")
                if df_raw_4h is not None and not df_raw_4h.empty:
                    higher_timeframes["240"] = df_raw_4h
                if df_raw_1d is not None and not df_raw_1d.empty:
                    higher_timeframes["D"] = df_raw_1d
            
            if higher_timeframes:
                df_features = feature_engineer.add_mtf_features(df_features, higher_timeframes)
                tf_names = "/".join(higher_timeframes.keys())
                safe_print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã MTF‚Äë–ø—Ä–∏–∑–Ω–∞–∫–∏ ({tf_names}). –í—Å–µ–≥–æ —Ñ–∏—á: {len(feature_engineer.get_feature_names())}")
            else:
                safe_print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã—Å—à–∏—Ö –¢–§ ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ {interval_display} –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.")
        
        feature_names = feature_engineer.get_feature_names()
        safe_print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) ===
        safe_print(f"\n[3/5] üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç)...")
        safe_print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        safe_print("   ‚Ä¢ Forward periods: 5 (75 –º–∏–Ω—É—Ç)")
        safe_print("   ‚Ä¢ Threshold: 0.3% (—É–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤)")
        safe_print("   ‚Ä¢ Min profit: 0.3% (—É–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤)")
        safe_print("   ‚Ä¢ Risk/Reward: 1.5:1")
        safe_print("   ‚Ä¢ Use ATR threshold: True")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ü–†–û–©–ï–ù–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        # –ö–†–ò–¢–ò–ß–ù–û: –£–º–µ–Ω—å—à–µ–Ω—ã –ø–æ—Ä–æ–≥–∏ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ (—Ü–µ–ª—å: 30-40%)
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=5 if base_interval == "15" else 2,  # 5 * 15m = 75 –º–∏–Ω—É—Ç –∏–ª–∏ 2 * 1h = 2 —á–∞—Å–∞
            threshold_pct=0.3,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 0.5% –¥–æ 0.3% –¥–ª—è –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=1.5,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 2.0 –¥–æ 1.5
            max_hold_periods=96 if base_interval == "15" else 24,  # 96 * 15m = 24 —á–∞—Å–∞ –∏–ª–∏ 24 * 1h = 24 —á–∞—Å–∞
            min_profit_pct=0.3,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 0.5% –¥–æ 0.3% –¥–ª—è –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        target_dist = df_with_target['target'].value_counts()
        safe_print(f"\n‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–∑–¥–∞–Ω–∞")
        safe_print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in target_dist.items():
            pct = count / len(df_with_target) * 100
            label_name = "LONG" if label == 1 else ("SHORT" if label == -1 else "HOLD")
            safe_print(f"   {label_name:5s}: {count:5d} ({pct:5.1f}%)")
        
        # === –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        safe_print(f"\n[4/5] üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        safe_print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        safe_print(f"   Features: {X.shape[0]} samples √ó {X.shape[1]} features")
        safe_print(f"   Target: {y.shape[0]} labels")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
        signal_count = (y != 0).sum()
        if signal_count < 50:
            safe_print(f"\n‚ö†Ô∏è  –ú–∞–ª–æ —Å–∏–≥–Ω–∞–ª–æ–≤ ({signal_count}). –°–º—è–≥—á–∞—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∞—Ä–≥–µ—Ç–∞...")
            # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ç–∞—Ä–≥–µ—Ç —Å –±–æ–ª–µ–µ –º—è–≥–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            df_with_target = feature_engineer.create_target_variable(
                df_features,
                forward_periods=4,  # –ú–µ–Ω—å—à–µ –ø–µ—Ä–∏–æ–¥–æ–≤
                threshold_pct=0.3,  # –ï—â–µ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥
                use_atr_threshold=True,
                use_risk_adjusted=False,  # –û—Ç–∫–ª—é—á–∞–µ–º —Ä–∏—Å–∫-—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                min_risk_reward_ratio=1.2,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π RR
                max_hold_periods=144,  # 36 —á–∞—Å–æ–≤
                min_profit_pct=0.3,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
            )
            X, y = feature_engineer.prepare_features_for_ml(df_with_target)
            signal_count = (y != 0).sum()
            safe_print(f"   –ü–æ—Å–ª–µ —Å–º—è–≥—á–µ–Ω–∏—è: {signal_count} —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # === –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ ===
        safe_print(f"\n[5/5] ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤...")
        trainer = ModelTrainer()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y)
        if len(classes) < 2:
            safe_print("‚ùå –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ.")
            continue
        
        base_weights = compute_class_weight('balanced', classes=classes, y=y)
        
        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: —É—á–∏—Ç—ã–≤–∞–µ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å LONG/SHORT
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        class_counts = {}
        for cls in classes:
            class_counts[cls] = (y == cls).sum()
        
        long_count = class_counts.get(1, 0)
        short_count = class_counts.get(-1, 0)
        hold_count = class_counts.get(0, 0)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º minority class (LONG –∏–ª–∏ SHORT)
        if long_count > 0 and short_count > 0:
            if long_count < short_count:
                minority_class = 1  # LONG
                majority_class = -1  # SHORT
                imbalance_ratio = short_count / long_count if long_count > 0 else 1.0
            else:
                minority_class = -1  # SHORT
                majority_class = 1  # LONG
                imbalance_ratio = long_count / short_count if short_count > 0 else 1.0
        else:
            minority_class = None
            majority_class = None
            imbalance_ratio = 1.0
        
        # –£–ú–ï–†–ï–ù–ù–´–ï –≤–µ—Å–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ —Å —É—á–µ—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ LONG/SHORT
        class_weight_dict = {}
        for i, cls in enumerate(classes):
            if cls == 0:  # HOLD
                class_weight_dict[cls] = base_weights[i] * 0.3  # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å HOLD
            else:  # LONG or SHORT
                base_weight = base_weights[i] * 2.0  # –ë–∞–∑–æ–≤–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å minority class
                if minority_class is not None and cls == minority_class and imbalance_ratio > 1.5:
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å minority class –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É
                    boost_factor = min(1.5, imbalance_ratio / 2.0)  # –ú–∞–∫—Å–∏–º—É–º 1.5x boost
                    class_weight_dict[cls] = base_weight * (1.0 + boost_factor)
                    safe_print(f"      –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å {('LONG' if cls == 1 else 'SHORT')} (minority) –Ω–∞ {boost_factor*100:.0f}% –∏–∑-–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞")
                else:
                    class_weight_dict[cls] = base_weight
        
        safe_print(f"\n   üìä –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
        for cls, weight in class_weight_dict.items():
            label_name = "LONG" if cls == 1 else ("SHORT" if cls == -1 else "HOLD")
            safe_print(f"      {label_name}: {weight:.2f}")
        
        # –û–±—É—á–∞–µ–º Random Forest
        safe_print(f"\n   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        rf_model, rf_metrics = trainer.train_random_forest_classifier(
            X, y,
            n_estimators=100,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            max_depth=10,
            class_weight=class_weight_dict,
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        rf_filename = f"rf_{symbol}_{base_interval}_{mode_suffix}.pkl"
        trainer.save_model(
            rf_model,
            trainer.scaler,
            feature_names,
            rf_metrics,
            rf_filename,
            symbol=symbol,
            interval=base_interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 100,
                "max_depth": 10,
                "forward_periods": 5,
                "threshold_pct": 0.5,
                "min_risk_reward_ratio": 1.5,
            },
        )
        safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {rf_filename}")
        safe_print(f"      üìä Accuracy: {rf_metrics['accuracy']:.4f}")
        safe_print(f"      üìä CV Accuracy: {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º XGBoost (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        try:
            # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å xgboost –Ω–∞–ø—Ä—è–º—É—é
            import xgboost
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è train_xgboost_classifier –¥–æ—Å—Ç—É–ø–Ω–∞
            if not hasattr(trainer, 'train_xgboost_classifier'):
                raise AttributeError("train_xgboost_classifier method not available")
            
            safe_print(f"\n   ‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost...")
            
            xgb_model, xgb_metrics = trainer.train_xgboost_classifier(
                X, y,
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                class_weight=class_weight_dict,
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            xgb_filename = f"xgb_{symbol}_{base_interval}_{mode_suffix}.pkl"
            trainer.save_model(
                xgb_model,
                trainer.scaler,
                feature_names,
                xgb_metrics,
                xgb_filename,
                symbol=symbol,
                interval=base_interval,
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "n_estimators": 100,
                    "max_depth": 6,
                    "learning_rate": 0.1,
                    "forward_periods": 5,
                    "threshold_pct": 0.5,
                    "min_risk_reward_ratio": 1.5,
                },
            )
            safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {xgb_filename}")
            safe_print(f"      üìä Accuracy: {xgb_metrics['accuracy']:.4f}")
            safe_print(f"      üìä CV Accuracy: {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
            
        except (ImportError, NameError) as e:
            safe_print(f"   ‚ö° XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            safe_print(f"      –î–µ—Ç–∞–ª–∏: {str(e)[:100]}")
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ xgboost –≤ —Å–∏—Å—Ç–µ–º–µ
            try:
                import subprocess
                import sys
                result = subprocess.run([sys.executable, "-c", "import xgboost; print(xgboost.__version__)"], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    safe_print(f"      ‚ö†Ô∏è  XGBoost —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ, –Ω–æ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ç–µ–∫—É—â–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏")
                    safe_print(f"      –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: pip install xgboost")
                else:
                    safe_print(f"      –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ XGBoost: pip install xgboost")
            except:
                pass
        
        # –û–±—É—á–∞–µ–º Ensemble (RF + XGBoost –µ—Å–ª–∏ –æ–±–∞ –µ—Å—Ç—å)
        try:
            rf_model
            xgb_model
            safe_print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ Ensemble (RF + XGBoost)...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            use_optimized = args.use_optimized_weights and symbol.upper() in optimized_weights
            rf_weight_opt = None
            xgb_weight_opt = None
            
            if use_optimized:
                symbol_weights = optimized_weights[symbol.upper()]
                # –ò—â–µ–º –≤–µ—Å–∞ –¥–ª—è RF –∏ XGB –º–æ–¥–µ–ª–µ–π
                for model_name, weight in symbol_weights.items():
                    if mode_suffix in model_name and symbol.upper() in model_name:
                        if model_name.startswith("rf_"):
                            rf_weight_opt = weight
                        elif model_name.startswith("xgb_"):
                            xgb_weight_opt = weight
                
                if rf_weight_opt is not None and xgb_weight_opt is not None:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
                    total = rf_weight_opt + xgb_weight_opt
                    if total > 0:
                        rf_weight_opt = rf_weight_opt / total
                        xgb_weight_opt = xgb_weight_opt / total
                        safe_print(f"   [OK] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞: RF={rf_weight_opt:.3f}, XGB={xgb_weight_opt:.3f}")
            
            # –û–±—É—á–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å (–≤–µ—Å–∞ –±—É–¥—É—Ç –≤—ã—á–∏—Å–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            if use_optimized and rf_weight_opt is not None and xgb_weight_opt is not None:
                # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –≤—Ä—É—á–Ω—É—é —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
                # –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
                ensemble_model, ensemble_metrics = trainer.train_ensemble(
                    X, y,
                    rf_n_estimators=100,
                    rf_max_depth=10,
                    xgb_n_estimators=100,
                    xgb_max_depth=6,
                    xgb_learning_rate=0.1,
                    ensemble_method="weighted_average",
                    class_weight=class_weight_dict,
                )
                # –ó–∞–º–µ–Ω—è–µ–º –∞–Ω—Å–∞–º–±–ª—å –Ω–∞ –Ω–æ–≤—ã–π —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
                ensemble_model = WeightedEnsemble(rf_model, xgb_model, rf_weight_opt, xgb_weight_opt)
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å –Ω–æ–≤—ã–º–∏ –≤–µ—Å–∞–º–∏
                ensemble_metrics['rf_weight'] = rf_weight_opt
                ensemble_metrics['xgb_weight'] = xgb_weight_opt
                safe_print(f"   [OK] –ê–Ω—Å–∞–º–±–ª—å —Å–æ–∑–¥–∞–Ω —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –≤–µ—Å–∞–º–∏
                ensemble_model, ensemble_metrics = trainer.train_ensemble(
                    X, y,
                    rf_n_estimators=100,
                    rf_max_depth=10,
                    xgb_n_estimators=100,
                    xgb_max_depth=6,
                    xgb_learning_rate=0.1,
                    ensemble_method="weighted_average",
                    class_weight=class_weight_dict,
                )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            ensemble_filename = f"ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
            trainer.save_model(
                ensemble_model,
                trainer.scaler,
                feature_names,
                ensemble_metrics,
                ensemble_filename,
                symbol=symbol,
                interval=base_interval,
                model_type="ensemble_weighted",
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "rf_n_estimators": 100,
                    "rf_max_depth": 10,
                    "xgb_n_estimators": 100,
                    "xgb_max_depth": 6,
                    "xgb_learning_rate": 0.1,
                    "ensemble_method": "weighted_average",
                    "forward_periods": 5,
                    "threshold_pct": 0.5,
                    "min_risk_reward_ratio": 1.5,
                    "optimized_weights": use_optimized and rf_weight_opt is not None,
                    "rf_weight": rf_weight_opt if use_optimized else ensemble_metrics.get('rf_weight'),
                    "xgb_weight": xgb_weight_opt if use_optimized else ensemble_metrics.get('xgb_weight'),
                },
            )
            safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {ensemble_filename}")
            safe_print(f"      üìä Accuracy: {ensemble_metrics['accuracy']:.4f}")
            safe_print(f"      üìä CV Accuracy: {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
            if use_optimized and rf_weight_opt is not None:
                safe_print(f"      üìä –í–µ—Å–∞: RF={rf_weight_opt:.3f}, XGB={xgb_weight_opt:.3f} (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)")
            
        except (NameError, ImportError):
            safe_print(f"   üéØ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å Ensemble. –¢—Ä–µ–±—É—é—Ç—Å—è RF –∏ XGBoost.")
        
        # –û–±—É—á–∞–µ–º TripleEnsemble (–µ—Å–ª–∏ –µ—Å—Ç—å LightGBM)
        try:
            import lightgbm
            from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
            if LIGHTGBM_AVAILABLE:
                safe_print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ TripleEnsemble (RF + XGBoost + LightGBM)...")
                
                # –û–±—É—á–∞–µ–º LightGBM –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è –≤—Ä—É—á–Ω—É—é
                lgb_model, lgb_metrics = trainer.train_lightgbm_classifier(
                    X, y,
                    n_estimators=100,
                    max_depth=6,
                    learning_rate=0.1,
                    class_weight=class_weight_dict,
                )
                
                # –î–ª—è TripleEnsemble –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è RF –∏ XGB, LightGBM –ø–æ–ª—É—á–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫
                use_optimized_triple = args.use_optimized_weights and symbol.upper() in optimized_weights
                rf_weight_triple = None
                xgb_weight_triple = None
                lgb_weight_triple = None
                
                if use_optimized_triple:
                    symbol_weights = optimized_weights[symbol.upper()]
                    for model_name, weight in symbol_weights.items():
                        if mode_suffix in model_name and symbol.upper() in model_name:
                            if model_name.startswith("rf_"):
                                rf_weight_triple = weight
                            elif model_name.startswith("xgb_"):
                                xgb_weight_triple = weight
                    
                    if rf_weight_triple is not None and xgb_weight_triple is not None:
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞ RF –∏ XGB, LightGBM –ø–æ–ª—É—á–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫
                        total_rf_xgb = rf_weight_triple + xgb_weight_triple
                        if total_rf_xgb > 0:
                            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º RF –∏ XGB –≤–µ—Å–∞, –æ—Å—Ç–∞–≤–ª—è—è –º–µ—Å—Ç–æ –¥–ª—è LightGBM
                            scale = 0.8  # 80% –¥–ª—è RF+XGB, 20% –¥–ª—è LightGBM
                            rf_weight_triple = (rf_weight_triple / total_rf_xgb) * scale
                            xgb_weight_triple = (xgb_weight_triple / total_rf_xgb) * scale
                            lgb_weight_triple = 1.0 - scale
                            safe_print(f"   [OK] –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞: RF={rf_weight_triple:.3f}, XGB={xgb_weight_triple:.3f}, LGB={lgb_weight_triple:.3f}")
                
                # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
                if use_optimized_triple and rf_weight_triple is not None and xgb_weight_triple is not None:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞
                    triple_ensemble_model = TripleEnsemble(rf_model, xgb_model, lgb_model, rf_weight_triple, xgb_weight_triple, lgb_weight_triple)
                    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤)
                    triple_ensemble_metrics = {
                        'accuracy': (
                            rf_metrics.get('accuracy', 0.0) * rf_weight_triple +
                            xgb_metrics.get('accuracy', 0.0) * xgb_weight_triple +
                            lgb_metrics.get('accuracy', 0.0) * lgb_weight_triple
                        ),
                        'cv_mean': (
                            rf_metrics.get('cv_mean', 0.0) * rf_weight_triple +
                            xgb_metrics.get('cv_mean', 0.0) * xgb_weight_triple +
                            lgb_metrics.get('cv_mean', 0.0) * lgb_weight_triple
                        ),
                        'cv_std': (
                            (rf_metrics.get('cv_std', 0.0) * rf_weight_triple +
                             xgb_metrics.get('cv_std', 0.0) * xgb_weight_triple +
                             lgb_metrics.get('cv_std', 0.0) * lgb_weight_triple) / 3.0
                        ),
                        'rf_weight': rf_weight_triple,
                        'xgb_weight': xgb_weight_triple,
                        'lgb_weight': lgb_weight_triple,
                        'rf_metrics': rf_metrics,
                        'xgb_metrics': xgb_metrics,
                        'lgb_metrics': lgb_metrics,
                    }
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –≤–µ—Å–∞–º–∏
                    triple_ensemble_model, triple_ensemble_metrics = trainer.train_ensemble(
                        X, y,
                        rf_n_estimators=100,
                        rf_max_depth=10,
                        xgb_n_estimators=100,
                        xgb_max_depth=6,
                        xgb_learning_rate=0.1,
                        lgb_n_estimators=100,
                        lgb_max_depth=6,
                        lgb_learning_rate=0.1,
                        ensemble_method="triple",
                        include_lightgbm=True,
                        class_weight=class_weight_dict,
                    )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                triple_filename = f"triple_ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
                trainer.save_model(
                    triple_ensemble_model,
                    trainer.scaler,
                    feature_names,
                    triple_ensemble_metrics,
                    triple_filename,
                    symbol=symbol,
                    interval=base_interval,
                    model_type="triple_ensemble",
                    class_weights=class_weight_dict,
                    class_distribution=target_dist.to_dict(),
                    training_params={
                        "rf_n_estimators": 100,
                        "rf_max_depth": 10,
                        "xgb_n_estimators": 100,
                        "xgb_max_depth": 6,
                        "xgb_learning_rate": 0.1,
                        "lgb_n_estimators": 100,
                        "lgb_max_depth": 6,
                        "lgb_learning_rate": 0.1,
                        "ensemble_method": "triple",
                        "forward_periods": 5,
                        "threshold_pct": 0.5,
                        "min_risk_reward_ratio": 1.5,
                        "optimized_weights": use_optimized_triple and rf_weight_triple is not None,
                        "rf_weight": rf_weight_triple if use_optimized_triple else triple_ensemble_metrics.get('rf_weight'),
                        "xgb_weight": xgb_weight_triple if use_optimized_triple else triple_ensemble_metrics.get('xgb_weight'),
                        "lgb_weight": lgb_weight_triple if use_optimized_triple else triple_ensemble_metrics.get('lgb_weight'),
                    },
                )
                safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {triple_filename}")
                safe_print(f"      üìä Accuracy: {triple_ensemble_metrics['accuracy']:.4f}")
                safe_print(f"      üìä CV Accuracy: {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
                if use_optimized_triple and rf_weight_triple is not None:
                    safe_print(f"      üìä –í–µ—Å–∞: RF={rf_weight_triple:.3f}, XGB={xgb_weight_triple:.3f}, LGB={lgb_weight_triple:.3f} (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)")
            else:
                safe_print(f"   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
        except ImportError:
            safe_print(f"   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
        
        # –û–±—É—á–∞–µ–º QuadEnsemble (RF + XGB + LGB + LSTM)
        try:
            from bot.ml.model_trainer import LSTM_AVAILABLE, LIGHTGBM_AVAILABLE
            if LSTM_AVAILABLE and LIGHTGBM_AVAILABLE:
                safe_print(f"\n   üöÄ –û–±—É—á–µ–Ω–∏–µ QuadEnsemble (RF + XGB + LGB + LSTM)...")
                safe_print(f"      (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...)")
                
                quad_ensemble_model, quad_metrics = trainer.train_quad_ensemble(
                    X, y,
                    df=df_with_target,  # –ü–µ—Ä–µ–¥–∞–µ–º DataFrame –¥–ª—è LSTM –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
                    rf_n_estimators=100,
                    rf_max_depth=10,
                    xgb_n_estimators=100,
                    xgb_max_depth=6,
                    xgb_learning_rate=0.1,
                    lgb_n_estimators=100,
                    lgb_max_depth=6,
                    lgb_learning_rate=0.1,
                    lstm_sequence_length=60,
                    lstm_epochs=20,  # 20 —ç–ø–æ—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø–µ—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
                    class_weight=class_weight_dict,
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                quad_filename = f"quad_ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
                trainer.save_model(
                    quad_ensemble_model,
                    trainer.scaler,
                    feature_names,
                    quad_metrics,
                    quad_filename,
                    symbol=symbol,
                    interval=base_interval,
                    model_type="quad_ensemble",
                    class_weights=class_weight_dict,
                    class_distribution=target_dist.to_dict(),
                    training_params={
                        "ensemble_method": "quad",
                        "lstm_epochs": 20,
                        "lstm_sequence_length": 60,
                        "forward_periods": 5,
                        "threshold_pct": 0.5,
                        "min_risk_reward_ratio": 1.5,
                    },
                )
                safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {quad_filename}")
                
                # –î–ª—è QuadEnsemble –º–µ—Ç—Ä–∏–∫–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
                rf_m = quad_metrics.get("rf_metrics", {})
                lstm_m = quad_metrics.get("lstm_metrics", {})
                
                safe_print(f"      üìä RF CV Accuracy: {rf_m.get('cv_mean', 0):.4f}")
                safe_print(f"      üìä LSTM Accuracy: {lstm_m.get('accuracy', 0):.4f}")
                
            else:
                missing = []
                if not LSTM_AVAILABLE: missing.append("LSTM (PyTorch)")
                if not LIGHTGBM_AVAILABLE: missing.append("LightGBM")
                safe_print(f"   ‚ö†Ô∏è  –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ({', '.join(missing)}), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º QuadEnsemble")
        except Exception as e:
            safe_print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ QuadEnsemble: {e}")
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        safe_print(f"\n" + "-" * 80)
        safe_print(f"üìä –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø {symbol}")
        safe_print("-" * 80)
        safe_print(f"\nüå≤ Random Forest:")
        safe_print(f"   Accuracy:     {rf_metrics['accuracy']:.4f}")
        safe_print(f"   CV Accuracy:  {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        if 'xgb_metrics' in locals():
            safe_print(f"\n‚ö° XGBoost:")
            safe_print(f"   Accuracy:     {xgb_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        if 'ensemble_metrics' in locals():
            safe_print(f"\nüéØ Ensemble (RF+XGB):")
            safe_print(f"   Accuracy:     {ensemble_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        
        if 'triple_ensemble_metrics' in locals():
            safe_print(f"\nüéØ TripleEnsemble (RF+XGB+LGB):")
            safe_print(f"   Accuracy:     {triple_ensemble_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")

        if 'quad_metrics' in locals():
            safe_print(f"\nüöÄ QuadEnsemble (RF+XGB+LGB+LSTM):")
            safe_print(f"   –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        models = []
        models.append(("Random Forest", rf_metrics['cv_mean']))
        if 'xgb_metrics' in locals():
            models.append(("XGBoost", xgb_metrics['cv_mean']))
        if 'ensemble_metrics' in locals():
            models.append(("Ensemble", ensemble_metrics['cv_mean']))
        if 'triple_ensemble_metrics' in locals():
            models.append(("TripleEnsemble", triple_ensemble_metrics['cv_mean']))
        if 'quad_metrics' in locals():
             # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ CV –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ –ø—Ä–æ–∫—Å–∏ + –±–æ–Ω—É—Å –∑–∞ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
             avg_cv = (rf_metrics['cv_mean'] + xgb_metrics.get('cv_mean', 0) + triple_ensemble_metrics.get('cv_mean', 0)) / 3
             models.append(("QuadEnsemble", avg_cv * 1.05)) # –£—Å–ª–æ–≤–Ω—ã–π –±–æ–Ω—É—Å
        
        if models:
            models.sort(key=lambda x: x[1], reverse=True)
            best_model, best_score = models[0]
            safe_print(f"\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {best_model}")
            safe_print(f"   Score: {best_score:.4f}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    safe_print("\n" + "=" * 80)
    safe_print("üéâ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    safe_print("=" * 80)
    safe_print("\nüì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    safe_print("   ‚Ä¢ ml_models/rf_*_15.pkl (Random Forest)")
    safe_print("   ‚Ä¢ ml_models/xgb_*_15.pkl (XGBoost)")
    safe_print("   ‚Ä¢ ml_models/ensemble_*_15.pkl (RF + XGBoost)")
    safe_print("   ‚Ä¢ ml_models/triple_ensemble_*_15.pkl (RF + XGBoost + LightGBM)")
    safe_print("   ‚Ä¢ ml_models/quad_ensemble_*_15.pkl (RF + XGBoost + LightGBM + LSTM)")
    safe_print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    safe_print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
    safe_print("      python test_ml_strategy.py --symbol SOLUSDT --days 7")
    safe_print("   2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ, –∑–∞–¥–µ–ø–ª–æ–π—Ç–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä")
    safe_print("=" * 80)


if __name__ == "__main__":
    main()