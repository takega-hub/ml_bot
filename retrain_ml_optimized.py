"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤.

–£–ª—É—á—à–µ–Ω–∏—è:
1. –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç (movement > 1%)
2. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (class_weight)
3. –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –¥–Ω–µ–π)
4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
"""
import warnings
import os
import sys

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows (–ë–ï–ó–û–ü–ê–°–ù–ê–Ø –í–ï–†–°–ò–Ø)
if sys.platform == 'win32':
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–º–µ–Ω—É –æ—à–∏–±–æ–∫ –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ stdout/stderr
        import codecs
        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω
        if sys.stdout.isatty():
            sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'replace')
        if sys.stderr.isatty():
            sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'replace')
    except:
        pass  # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
warnings.filterwarnings('ignore')

from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from bot.config import load_settings
from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ (–∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è Windows)
def safe_print(*args, **kwargs):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π print, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏."""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–≤–µ—Å—Ç–∏ –∫–∞–∫ –µ—Å—Ç—å
        print(*args, **kwargs)
        sys.stdout.flush()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
    except (UnicodeEncodeError, IOError) as e:
        try:
            # –ó–∞–º–µ–Ω—è–µ–º —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏
            text = ' '.join(str(arg) for arg in args)
            # –û—Å–Ω–æ–≤–Ω—ã–µ —ç–º–æ–¥–∑–∏
            replacements = {
                'üöÄ': '[START]',
                'üìä': '[INFO]', 
                '‚úÖ': '[OK]',
                '‚ùå': '[ERROR]',
                '‚è≥': '[WAIT]',
                'üî•': '[HOT]',
                'üì•': '[DOWNLOAD]',
                'üîß': '[ENGINEERING]',
                'üéØ': '[TARGET]',
                'üì¶': '[DATA]',
                'ü§ñ': '[MODEL]',
                'üå≤': '[RF]',
                '‚ö°': '[XGB]',
                'üéâ': '[SUCCESS]',
                'üí°': '[TIP]',
                'üîÑ': '[RETRAIN]',
                'üìã': '[LIST]',
                'üîç': '[SEARCH]',
                'üìà': '[CHART]',
                'üß™': '[TEST]',
                '‚öôÔ∏è': '[SETTINGS]'
            }
            for emoji, replacement in replacements.items():
                text = text.replace(emoji, replacement)
            
            # –í—ã–≤–æ–¥–∏–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            print(text, **kwargs)
            sys.stdout.flush()
        except:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –≤—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
            try:
                text = ' '.join(str(arg) for arg in args)
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ã
                text = ''.join(c for c in text if ord(c) < 128)
                print(text, **kwargs)
            except:
                print("[ERROR: Could not print message]", **kwargs)


def main():
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", type=str, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    args = parser.parse_known_args()[0]
    
    safe_print("=" * 80)
    safe_print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò")
    safe_print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = load_settings()
    
    # –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    symbols = [args.symbol] if args.symbol else ["SOLUSDT", "BTCUSDT", "ETHUSDT", "XRPUSDT"]
    base_interval = "15"  # 15 –º–∏–Ω—É—Ç (–±–∞–∑–æ–≤—ã–π –¢–§)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ MTF-—Ä–µ–∂–∏–º –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (—á–∏—Ç–∞–µ–º –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
    ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "1")
    ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")
    mode_suffix = "mtf" if ml_mtf_enabled else "15m"
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
        safe_print("\n" + "=" * 80)
        safe_print(f"üìä –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø {symbol}")
        safe_print("=" * 80)
        
        # === –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (30 –¥–Ω–µ–π) ===
        if ml_mtf_enabled:
            safe_print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (15m, 1h, 4h) –¥–ª—è {symbol}...")
        else:
            safe_print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (15m only) –¥–ª—è {symbol}...")
        collector = DataCollector(settings.api)
        
        if ml_mtf_enabled:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            mtf_data = collector.collect_multiple_timeframes(
                symbol=symbol,
                intervals=[base_interval, "60", "240"],  # 15m, 1h, 4h
                start_date=None,
                end_date=None,
            )
            
            df_raw_15m = mtf_data.get(base_interval)
            df_raw_1h = mtf_data.get("60")
            df_raw_4h = mtf_data.get("240")
            
            if df_raw_15m is None or df_raw_15m.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (15m) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_15m)} —Å–≤–µ—á–µ–π 15m (~{len(df_raw_15m)/96:.1f} –¥–Ω–µ–π)")
        else:
            # –°—Ç–∞—Ä—ã–π —Ä–µ–∂–∏–º: —Å–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ 15m –¥–∞–Ω–Ω—ã–µ
            df_raw_15m = collector.collect_klines(
                symbol=symbol,
                interval=base_interval,
                start_date=None,
                end_date=None,
                limit=3000,
            )
            if df_raw_15m.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (15m) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_15m)} —Å–≤–µ—á–µ–π 15m (~{len(df_raw_15m)/96:.1f} –¥–Ω–µ–π)")
        
        # === –®–∞–≥ 2: Feature Engineering ===
        safe_print(f"\n[2/5] üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}...")
        feature_engineer = FeatureEngineer()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –±–∞–∑–æ–≤–æ–º –¢–§ (15m)
        df_features = feature_engineer.create_technical_indicators(df_raw_15m)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º—É–ª—å—Ç–∏‚Äë—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (1h, 4h), –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å –∏ MTF –≤–∫–ª—é—á–µ–Ω
        if ml_mtf_enabled:
            higher_timeframes = {}
            df_raw_1h = mtf_data.get("60")
            df_raw_4h = mtf_data.get("240")
            if df_raw_1h is not None and not df_raw_1h.empty:
                higher_timeframes["60"] = df_raw_1h
            if df_raw_4h is not None and not df_raw_4h.empty:
                higher_timeframes["240"] = df_raw_4h
            
            if higher_timeframes:
                df_features = feature_engineer.add_mtf_features(df_features, higher_timeframes)
                safe_print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã MTF‚Äë–ø—Ä–∏–∑–Ω–∞–∫–∏ (1h/4h). –í—Å–µ–≥–æ —Ñ–∏—á: {len(feature_engineer.get_feature_names())}")
            else:
                safe_print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è 1h/4h ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ 15m –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.")
        
        feature_names = feature_engineer.get_feature_names()
        safe_print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) ===
        safe_print(f"\n[3/5] üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç)...")
        safe_print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        safe_print("   ‚Ä¢ Forward periods: 5 (75 –º–∏–Ω—É—Ç)")
        safe_print("   ‚Ä¢ Threshold: 1.0% (–≤–º–µ—Å—Ç–æ 0.2%)")
        safe_print("   ‚Ä¢ Risk/Reward: 1.5:1")
        safe_print("   ‚Ä¢ Use ATR threshold: True")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ü–†–û–©–ï–ù–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=5,  # 5 * 15m = 75 –º–∏–Ω—É—Ç
            threshold_pct=0.5,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 1.0% –¥–æ 0.5% –¥–ª—è –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=1.5,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 2.0 –¥–æ 1.5
            max_hold_periods=96,  # –£–í–ï–õ–ò–ß–ï–ù–û —Å 48 –¥–æ 96 (24 —á–∞—Å–∞)
            min_profit_pct=0.5,  # –£–ú–ï–ù–¨–®–ï–ù–û —Å 1.0% –¥–æ 0.5%
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        target_dist = df_with_target['target'].value_counts()
        safe_print(f"\n‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–∑–¥–∞–Ω–∞")
        safe_print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in target_dist.items():
            pct = count / len(df_with_target) * 100
            label_name = "LONG" if label == 1 else ("SHORT" if label == -1 else "HOLD")
            safe_print(f"   {label_name:5s}: {count:5d} ({pct:5.1f}%)")
        
        # === –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        safe_print(f"\n[4/5] üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        safe_print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        safe_print(f"   Features: {X.shape[0]} samples √ó {X.shape[1]} features")
        safe_print(f"   Target: {y.shape[0]} labels")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
        signal_count = (y != 0).sum()
        if signal_count < 50:
            safe_print(f"\n‚ö†Ô∏è  –ú–∞–ª–æ —Å–∏–≥–Ω–∞–ª–æ–≤ ({signal_count}). –°–º—è–≥—á–∞—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∞—Ä–≥–µ—Ç–∞...")
            # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ç–∞—Ä–≥–µ—Ç —Å –±–æ–ª–µ–µ –º—è–≥–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            df_with_target = feature_engineer.create_target_variable(
                df_features,
                forward_periods=4,  # –ú–µ–Ω—å—à–µ –ø–µ—Ä–∏–æ–¥–æ–≤
                threshold_pct=0.3,  # –ï—â–µ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥
                use_atr_threshold=True,
                use_risk_adjusted=False,  # –û—Ç–∫–ª—é—á–∞–µ–º —Ä–∏—Å–∫-—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                min_risk_reward_ratio=1.2,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π RR
                max_hold_periods=144,  # 36 —á–∞—Å–æ–≤
                min_profit_pct=0.3,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
            )
            X, y = feature_engineer.prepare_features_for_ml(df_with_target)
            signal_count = (y != 0).sum()
            safe_print(f"   –ü–æ—Å–ª–µ —Å–º—è–≥—á–µ–Ω–∏—è: {signal_count} —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # === –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ ===
        safe_print(f"\n[5/5] ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤...")
        trainer = ModelTrainer()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y)
        if len(classes) < 2:
            safe_print("‚ùå –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ.")
            continue
        
        base_weights = compute_class_weight('balanced', classes=classes, y=y)
        
        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: —É—á–∏—Ç—ã–≤–∞–µ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å LONG/SHORT
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        class_counts = {}
        for cls in classes:
            class_counts[cls] = (y == cls).sum()
        
        long_count = class_counts.get(1, 0)
        short_count = class_counts.get(-1, 0)
        hold_count = class_counts.get(0, 0)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º minority class (LONG –∏–ª–∏ SHORT)
        if long_count > 0 and short_count > 0:
            if long_count < short_count:
                minority_class = 1  # LONG
                majority_class = -1  # SHORT
                imbalance_ratio = short_count / long_count if long_count > 0 else 1.0
            else:
                minority_class = -1  # SHORT
                majority_class = 1  # LONG
                imbalance_ratio = long_count / short_count if short_count > 0 else 1.0
        else:
            minority_class = None
            majority_class = None
            imbalance_ratio = 1.0
        
        # –£–ú–ï–†–ï–ù–ù–´–ï –≤–µ—Å–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ —Å —É—á–µ—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ LONG/SHORT
        class_weight_dict = {}
        for i, cls in enumerate(classes):
            if cls == 0:  # HOLD
                class_weight_dict[cls] = base_weights[i] * 0.3  # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å HOLD
            else:  # LONG or SHORT
                base_weight = base_weights[i] * 2.0  # –ë–∞–∑–æ–≤–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å minority class
                if minority_class is not None and cls == minority_class and imbalance_ratio > 1.5:
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å minority class –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É
                    boost_factor = min(1.5, imbalance_ratio / 2.0)  # –ú–∞–∫—Å–∏–º—É–º 1.5x boost
                    class_weight_dict[cls] = base_weight * (1.0 + boost_factor)
                    safe_print(f"      –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å {('LONG' if cls == 1 else 'SHORT')} (minority) –Ω–∞ {boost_factor*100:.0f}% –∏–∑-–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞")
                else:
                    class_weight_dict[cls] = base_weight
        
        safe_print(f"\n   üìä –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
        for cls, weight in class_weight_dict.items():
            label_name = "LONG" if cls == 1 else ("SHORT" if cls == -1 else "HOLD")
            safe_print(f"      {label_name}: {weight:.2f}")
        
        # –û–±—É—á–∞–µ–º Random Forest
        safe_print(f"\n   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        rf_model, rf_metrics = trainer.train_random_forest_classifier(
            X, y,
            n_estimators=100,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            max_depth=10,
            class_weight=class_weight_dict,
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        rf_filename = f"rf_{symbol}_{base_interval}_{mode_suffix}.pkl"
        trainer.save_model(
            rf_model,
            trainer.scaler,
            feature_names,
            rf_metrics,
            rf_filename,
            symbol=symbol,
            interval=base_interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 100,
                "max_depth": 10,
                "forward_periods": 5,
                "threshold_pct": 0.5,
                "min_risk_reward_ratio": 1.5,
            },
        )
        safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {rf_filename}")
        safe_print(f"      üìä Accuracy: {rf_metrics['accuracy']:.4f}")
        safe_print(f"      üìä CV Accuracy: {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º XGBoost (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        try:
            import xgboost
            safe_print(f"\n   ‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost...")
            
            xgb_model, xgb_metrics = trainer.train_xgboost_classifier(
                X, y,
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                class_weight=class_weight_dict,
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            xgb_filename = f"xgb_{symbol}_{base_interval}_{mode_suffix}.pkl"
            trainer.save_model(
                xgb_model,
                trainer.scaler,
                feature_names,
                xgb_metrics,
                xgb_filename,
                symbol=symbol,
                interval=base_interval,
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "n_estimators": 100,
                    "max_depth": 6,
                    "learning_rate": 0.1,
                    "forward_periods": 5,
                    "threshold_pct": 0.5,
                    "min_risk_reward_ratio": 1.5,
                },
            )
            safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {xgb_filename}")
            safe_print(f"      üìä Accuracy: {xgb_metrics['accuracy']:.4f}")
            safe_print(f"      üìä CV Accuracy: {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
            
        except ImportError:
            safe_print(f"   ‚ö° XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        
        # –û–±—É—á–∞–µ–º Ensemble (RF + XGBoost –µ—Å–ª–∏ –æ–±–∞ –µ—Å—Ç—å)
        try:
            rf_model
            xgb_model
            safe_print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ Ensemble (RF + XGBoost)...")
            ensemble_model, ensemble_metrics = trainer.train_ensemble(
                X, y,
                rf_n_estimators=100,
                rf_max_depth=10,
                xgb_n_estimators=100,
                xgb_max_depth=6,
                xgb_learning_rate=0.1,
                ensemble_method="weighted_average",
                class_weight=class_weight_dict,
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            ensemble_filename = f"ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
            trainer.save_model(
                ensemble_model,
                trainer.scaler,
                feature_names,
                ensemble_metrics,
                ensemble_filename,
                symbol=symbol,
                interval=base_interval,
                model_type="ensemble_weighted",
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "rf_n_estimators": 100,
                    "rf_max_depth": 10,
                    "xgb_n_estimators": 100,
                    "xgb_max_depth": 6,
                    "xgb_learning_rate": 0.1,
                    "ensemble_method": "weighted_average",
                    "forward_periods": 5,
                    "threshold_pct": 0.5,
                    "min_risk_reward_ratio": 1.5,
                },
            )
            safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {ensemble_filename}")
            safe_print(f"      üìä Accuracy: {ensemble_metrics['accuracy']:.4f}")
            safe_print(f"      üìä CV Accuracy: {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
            
        except (NameError, ImportError):
            safe_print(f"   üéØ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å Ensemble. –¢—Ä–µ–±—É—é—Ç—Å—è RF –∏ XGBoost.")
        
        # –û–±—É—á–∞–µ–º TripleEnsemble (–µ—Å–ª–∏ –µ—Å—Ç—å LightGBM)
        try:
            import lightgbm
            from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
            if LIGHTGBM_AVAILABLE:
                safe_print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ TripleEnsemble (RF + XGBoost + LightGBM)...")
                triple_ensemble_model, triple_ensemble_metrics = trainer.train_ensemble(
                    X, y,
                    rf_n_estimators=100,
                    rf_max_depth=10,
                    xgb_n_estimators=100,
                    xgb_max_depth=6,
                    xgb_learning_rate=0.1,
                    lgb_n_estimators=100,
                    lgb_max_depth=6,
                    lgb_learning_rate=0.1,
                    ensemble_method="triple",
                    include_lightgbm=True,
                    class_weight=class_weight_dict,
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                triple_filename = f"triple_ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
                trainer.save_model(
                    triple_ensemble_model,
                    trainer.scaler,
                    feature_names,
                    triple_ensemble_metrics,
                    triple_filename,
                    symbol=symbol,
                    interval=base_interval,
                    model_type="triple_ensemble",
                    class_weights=class_weight_dict,
                    class_distribution=target_dist.to_dict(),
                    training_params={
                        "rf_n_estimators": 100,
                        "rf_max_depth": 10,
                        "xgb_n_estimators": 100,
                        "xgb_max_depth": 6,
                        "xgb_learning_rate": 0.1,
                        "lgb_n_estimators": 100,
                        "lgb_max_depth": 6,
                        "lgb_learning_rate": 0.1,
                        "ensemble_method": "triple",
                        "forward_periods": 5,
                        "threshold_pct": 0.5,
                        "min_risk_reward_ratio": 1.5,
                    },
                )
                safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {triple_filename}")
                safe_print(f"      üìä Accuracy: {triple_ensemble_metrics['accuracy']:.4f}")
                safe_print(f"      üìä CV Accuracy: {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            else:
                safe_print(f"   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
        except ImportError:
            safe_print(f"   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
        
        # –û–±—É—á–∞–µ–º QuadEnsemble (RF + XGB + LGB + LSTM)
        try:
            from bot.ml.model_trainer import LSTM_AVAILABLE, LIGHTGBM_AVAILABLE
            if LSTM_AVAILABLE and LIGHTGBM_AVAILABLE:
                safe_print(f"\n   üöÄ –û–±—É—á–µ–Ω–∏–µ QuadEnsemble (RF + XGB + LGB + LSTM)...")
                safe_print(f"      (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...)")
                
                quad_ensemble_model, quad_metrics = trainer.train_quad_ensemble(
                    X, y,
                    df=df_with_target,  # –ü–µ—Ä–µ–¥–∞–µ–º DataFrame –¥–ª—è LSTM –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
                    rf_n_estimators=100,
                    rf_max_depth=10,
                    xgb_n_estimators=100,
                    xgb_max_depth=6,
                    xgb_learning_rate=0.1,
                    lgb_n_estimators=100,
                    lgb_max_depth=6,
                    lgb_learning_rate=0.1,
                    lstm_sequence_length=60,
                    lstm_epochs=20,  # 20 —ç–ø–æ—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø–µ—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
                    class_weight=class_weight_dict,
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                quad_filename = f"quad_ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl"
                trainer.save_model(
                    quad_ensemble_model,
                    trainer.scaler,
                    feature_names,
                    quad_metrics,
                    quad_filename,
                    symbol=symbol,
                    interval=base_interval,
                    model_type="quad_ensemble",
                    class_weights=class_weight_dict,
                    class_distribution=target_dist.to_dict(),
                    training_params={
                        "ensemble_method": "quad",
                        "lstm_epochs": 20,
                        "lstm_sequence_length": 60,
                        "forward_periods": 5,
                        "threshold_pct": 0.5,
                        "min_risk_reward_ratio": 1.5,
                    },
                )
                safe_print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {quad_filename}")
                
                # –î–ª—è QuadEnsemble –º–µ—Ç—Ä–∏–∫–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
                rf_m = quad_metrics.get("rf_metrics", {})
                lstm_m = quad_metrics.get("lstm_metrics", {})
                
                safe_print(f"      üìä RF CV Accuracy: {rf_m.get('cv_mean', 0):.4f}")
                safe_print(f"      üìä LSTM Accuracy: {lstm_m.get('accuracy', 0):.4f}")
                
            else:
                missing = []
                if not LSTM_AVAILABLE: missing.append("LSTM (PyTorch)")
                if not LIGHTGBM_AVAILABLE: missing.append("LightGBM")
                safe_print(f"   ‚ö†Ô∏è  –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ({', '.join(missing)}), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º QuadEnsemble")
        except Exception as e:
            safe_print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ QuadEnsemble: {e}")
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        safe_print(f"\n" + "-" * 80)
        safe_print(f"üìä –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø {symbol}")
        safe_print("-" * 80)
        safe_print(f"\nüå≤ Random Forest:")
        safe_print(f"   Accuracy:     {rf_metrics['accuracy']:.4f}")
        safe_print(f"   CV Accuracy:  {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        if 'xgb_metrics' in locals():
            safe_print(f"\n‚ö° XGBoost:")
            safe_print(f"   Accuracy:     {xgb_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        if 'ensemble_metrics' in locals():
            safe_print(f"\nüéØ Ensemble (RF+XGB):")
            safe_print(f"   Accuracy:     {ensemble_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        
        if 'triple_ensemble_metrics' in locals():
            safe_print(f"\nüéØ TripleEnsemble (RF+XGB+LGB):")
            safe_print(f"   Accuracy:     {triple_ensemble_metrics['accuracy']:.4f}")
            safe_print(f"   CV Accuracy:  {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")

        if 'quad_metrics' in locals():
            safe_print(f"\nüöÄ QuadEnsemble (RF+XGB+LGB+LSTM):")
            safe_print(f"   –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        models = []
        models.append(("Random Forest", rf_metrics['cv_mean']))
        if 'xgb_metrics' in locals():
            models.append(("XGBoost", xgb_metrics['cv_mean']))
        if 'ensemble_metrics' in locals():
            models.append(("Ensemble", ensemble_metrics['cv_mean']))
        if 'triple_ensemble_metrics' in locals():
            models.append(("TripleEnsemble", triple_ensemble_metrics['cv_mean']))
        if 'quad_metrics' in locals():
             # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ CV –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ –ø—Ä–æ–∫—Å–∏ + –±–æ–Ω—É—Å –∑–∞ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
             avg_cv = (rf_metrics['cv_mean'] + xgb_metrics.get('cv_mean', 0) + triple_ensemble_metrics.get('cv_mean', 0)) / 3
             models.append(("QuadEnsemble", avg_cv * 1.05)) # –£—Å–ª–æ–≤–Ω—ã–π –±–æ–Ω—É—Å
        
        if models:
            models.sort(key=lambda x: x[1], reverse=True)
            best_model, best_score = models[0]
            safe_print(f"\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {best_model}")
            safe_print(f"   Score: {best_score:.4f}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    safe_print("\n" + "=" * 80)
    safe_print("üéâ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    safe_print("=" * 80)
    safe_print("\nüì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    safe_print("   ‚Ä¢ ml_models/rf_*_15.pkl (Random Forest)")
    safe_print("   ‚Ä¢ ml_models/xgb_*_15.pkl (XGBoost)")
    safe_print("   ‚Ä¢ ml_models/ensemble_*_15.pkl (RF + XGBoost)")
    safe_print("   ‚Ä¢ ml_models/triple_ensemble_*_15.pkl (RF + XGBoost + LightGBM)")
    safe_print("   ‚Ä¢ ml_models/quad_ensemble_*_15.pkl (RF + XGBoost + LightGBM + LSTM)")
    safe_print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    safe_print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
    safe_print("      python test_ml_strategy.py --symbol SOLUSDT --days 7")
    safe_print("   2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ, –∑–∞–¥–µ–ø–ª–æ–π—Ç–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä")
    safe_print("=" * 80)


if __name__ == "__main__":
    main()